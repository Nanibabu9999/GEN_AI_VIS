{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Create main.py"
      ],
      "metadata": {
        "id": "Rbn48ZKDLk-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from transformers import YolosImageProcessor, YolosForObjectDetection\n",
        "from PIL import Image, ImageDraw\n",
        "import torch\n",
        "\n",
        "# Load the model and image processor\n",
        "model = YolosForObjectDetection.from_pretrained('hustvl/yolos-tiny')\n",
        "image_processor = YolosImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
        "\n",
        "st.title(\"YOLOs Object Detection with Bounding Boxes\")\n",
        "\n",
        "# Upload image\n",
        "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Display uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "    # Process the image and run object detection\n",
        "    st.write(\"Detecting objects...\")\n",
        "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Process the results\n",
        "    target_sizes = torch.tensor([image.size[::-1]])\n",
        "    results = image_processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
        "\n",
        "    # Draw bounding boxes on the image\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "        box = [round(i, 2) for i in box.tolist()]\n",
        "        draw.rectangle(box, outline=\"red\", width=3)\n",
        "        draw.text((box[0], box[1]), f\"{model.config.id2label[label.item()]}: {round(score.item(), 3)}\", fill=\"red\")\n",
        "\n",
        "    # Display the image with bounding boxes\n",
        "    st.image(image, caption='Detected Objects', use_column_width=True)\n",
        "\n",
        "    # Optionally, display detection results in text form\n",
        "    st.write(\"Detection Results:\")\n",
        "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "        st.write(f\"Detected {model.config.id2label[label.item()]} with confidence {round(score.item(), 3)} at location {box}\")\n"
      ],
      "metadata": {
        "id": "asdssgJ-ImiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Replace main.py with the below for LLM capability"
      ],
      "metadata": {
        "id": "QlVxNog69eio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependency\n",
        "# !pip install groq\n",
        "# !pip install transformers\n",
        "# !pip install torch\n",
        "# !pip install streamlit\n",
        "# !pip install pillow\n",
        "\n",
        "# Import necessary libraries\n",
        "from groq import Groq\n",
        "import streamlit as st\n",
        "from transformers import YolosImageProcessor, YolosForObjectDetection\n",
        "from PIL import Image, ImageDraw\n",
        "import torch\n",
        "\n",
        "# Initialize Groq LLM with your API key\n",
        "llm = Groq(api_key=\"APIKEY\")  # Replace with your actual Groq API key\n",
        "\n",
        "# Load the YOLOs model and image processor\n",
        "model = YolosForObjectDetection.from_pretrained('hustvl/yolos-tiny')\n",
        "image_processor = YolosImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
        "\n",
        "# Streamlit app title\n",
        "st.title(\"YOLOs Object Detection with Groq Summarization\")\n",
        "\n",
        "# Upload image\n",
        "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Display uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "    # Process the image and run object detection\n",
        "    st.write(\"Detecting objects...\")\n",
        "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Process the results\n",
        "    target_sizes = torch.tensor([image.size[::-1]])\n",
        "    results = image_processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
        "\n",
        "    # Extract detection results\n",
        "    detection_results = []\n",
        "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "        detection_results.append(\n",
        "            f\"Detected {model.config.id2label[label.item()]} with confidence {round(score.item(), 3)} at location {box.tolist()}\"\n",
        "        )\n",
        "\n",
        "    # Send detection results to Groq for summarization\n",
        "    groq_prompt = \"Summarize the following object detection results: \" + \"; \".join(detection_results)\n",
        "    response = llm.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an AI specialized in summarizing object detection results.\"},\n",
        "            {\"role\": \"user\", \"content\": groq_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Extract the content of the response\n",
        "    response_content = response.choices[0].message.content\n",
        "\n",
        "    # Display the summarized results\n",
        "    st.write(\"Summary of Detection Results:\")\n",
        "    st.write(response_content)\n",
        "\n",
        "    # Draw bounding boxes on the image\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "        box = [round(i, 2) for i in box.tolist()]\n",
        "        draw.rectangle(box, outline=\"red\", width=3)\n",
        "        draw.text((box[0], box[1]), f\"{model.config.id2label[label.item()]}: {round(score.item(), 3)}\", fill=\"red\")\n",
        "\n",
        "    # Display the image with bounding boxes\n",
        "    st.image(image, caption='Detected Objects', use_column_width=True)\n"
      ],
      "metadata": {
        "id": "3UNFM9YF8LrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a requirements.txt for first cell"
      ],
      "metadata": {
        "id": "XxERY6AFLjkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit\n",
        "transformers\n",
        "torch\n",
        "Pillow"
      ],
      "metadata": {
        "id": "A7CyJmW2I5Sq",
        "outputId": "138e7185-a964-4b2e-ea7d-96b69487b3c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'streamlit' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-be9776746df9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstreamlit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhuggingface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcommunity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'streamlit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "requirements.txt if you are running second program with LLM groq"
      ],
      "metadata": {
        "id": "W28QFsS19ZB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit\n",
        "transformers\n",
        "torch\n",
        "Pillow\n",
        "groq"
      ],
      "metadata": {
        "id": "4eUP9xgA9HzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Ko0_bTf-3UrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run main.py\n",
        "\n",
        "or\n",
        "\n",
        "python -m streamlit run main.py"
      ],
      "metadata": {
        "id": "_PHOvMlep1nf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}