{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97UOI19nH9Gl",
        "outputId": "c78f9f53-21d3-4444-e042-3fd7c01a7a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.5/391.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-groq langchain-experimental\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VUCkEdEF2f8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01qXr4jPHnH1"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "\n",
        "# Initialize the Groq LLM\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    model_name=\"mixtral-8x7b-32768\"  # Replace with your desired model\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atEddXO1B1-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156431b4-fe5f-4cb4-fe80-eee884ca6240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm_math/base.py:56: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMMathChain\n",
        "\n",
        "# Create the LLMMathChain using the Groq LLM\n",
        "llm_math = LLMMathChain(llm=llm)\n",
        "\n",
        "# Initialize the math tool\n",
        "math_tool = Tool(\n",
        "    name='Calculator',\n",
        "    func=llm_math.run,\n",
        "    description='Useful for when you need to answer questions about math.'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-sxCbhtIqTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f8aa1c-059d-4458-896d-0b7acb81996a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Create a general-purpose LLM tool\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"{query}\"\n",
        ")\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Initialize the LLM tool\n",
        "llm_tool = Tool(\n",
        "    name='Language Model',\n",
        "    func=llm_chain.run,\n",
        "    description='Use this tool for general purpose queries and logic'\n",
        ")\n",
        "\n",
        "# Combine the tools\n",
        "tools = [math_tool, llm_tool]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlGXFuSgh7kW",
        "outputId": "6000024e-c0b2-4a3c-e708-7bdd8ed0fc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "# Initialize the zero-shot agent with the tools\n",
        "zero_shot_agent = initialize_agent(\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOYwjJ9abLa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1261e95f-ccaf-45b3-c98c-9ff2981b779d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe question is asking which of the two numbers, 9.9 or 9.11, is greater. This is a comparison question that involves numbers, so I can use the Calculator tool to determine the answer.\n",
            "\n",
            "Action: Calculator\n",
            "Action Input: 9.9 > 9.11\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: True\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe calculator has returned True, which means 9.9 is indeed greater than 9.11.\n",
            "Final Answer: 9.9 is greater than 9.11.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '9.9 is greater or 9.11 is greater',\n",
              " 'output': '9.9 is greater than 9.11.'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "zero_shot_agent(\"9.9 is greater or 9.11 is greater\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BbA0ttRa3yG"
      },
      "outputs": [],
      "source": [
        "tools.append(llm_tool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdI_4nkMcMMC",
        "outputId": "07cbf82d-daa8-4411-c6ec-fdb2691666ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI don't have this information readily available, I will need to use the Language Model tool to find the answer.\n",
            "Action: Language Model\n",
            "Action Input: What is the capital of Norway?\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mThe capital of Norway is Oslo. Established around 1000 AD, Oslo is the oldest of the Scandinavian capitals. Modern Oslo is a cosmopolitan city with a diverse population and a rich cultural scene, home to numerous museums, galleries, and theaters, as well as a vibrant nightlife. It is also known for its beautiful parks and gardens, and its proximity to nature, with forests, mountains, and fjords all within easy reach of the city center.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The capital of Norway is Oslo.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is the capital of Norway?',\n",
              " 'output': 'The capital of Norway is Oslo.'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "zero_shot_agent(\"what is the capital of Norway?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTf_4U4JcOkv",
        "outputId": "f5744fdc-d4ff-4c52-b814-497023cc1230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo answer this question, I need to perform a series of mathematical operations. I'll first multiply 4.5 and 2.1, then raise the result to the power of 2.2. I can use the Calculator tool for this.\n",
            "\n",
            "Action: Calculator\n",
            "Action Input: (4.5*2.1)**2.2\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: The value of (4.5*2.1)^2.2 is approximately 139.94.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is (4.5*2.1)^2.2?',\n",
              " 'output': 'The value of (4.5*2.1)^2.2 is approximately 139.94.'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "zero_shot_agent(\"What is (4.5*2.1)^2.2?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for the CSV agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
        "\n",
        "# Create the CSV agent\n",
        "csv_agent = create_csv_agent(\n",
        "    llm,  # Using the Groq LLM we initialized earlier\n",
        "    \"/content/insurance.csv\",  # Replace with the path to your CSV file\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    allow_dangerous_code=True  # Add this line to enable the feature\n",
        ")\n",
        "\n",
        "# Example query to interact with the CSV\n",
        "response = csv_agent(\"How many females having bmi less than 30?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5LNLmSXkoLD",
        "outputId": "8532a87e-2890-4e49-bf33-3230bcd01775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to filter the dataframe for rows where sex is 'female' and bmi is less than 30. Then, I can count the number of rows that meet these conditions.\n",
            "\n",
            "Action: python_repl_ast\n",
            "Action Input: len(df[(df['sex'] == 'female') & (df['bmi'] < 30)])\u001b[0m\u001b[36;1m\u001b[1;3m328\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: There are 328 females having a BMI less than 30.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'How many females having bmi less than 30?', 'output': 'There are 328 females having a BMI less than 30.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wT2tB30sklx"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}