{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Hierarchy Agents**\n",
        "\n",
        "**Judge - Debate between A vs B.**"
      ],
      "metadata": {
        "id": "GYYrYCQazOLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyautogen\n",
        "!pip install python-dotenv\n",
        "!pip install \"pyautogen[groq]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpDmyOnRqu5L",
        "outputId": "2ee4a418-a289-49d5-f815-de97eed6b75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen\n",
            "  Downloading pyautogen-0.2.35-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting diskcache (from pyautogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from pyautogen)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting flaml (from pyautogen)\n",
            "  Downloading FLAML-2.2.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.26.4)\n",
            "Collecting openai>=1.3 (from pyautogen)\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen) (24.1)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.8.2)\n",
            "Collecting python-dotenv (from pyautogen)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.4.0)\n",
            "Collecting tiktoken (from pyautogen)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.3->pyautogen)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.20.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen) (2024.5.15)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.3.2)\n",
            "Downloading pyautogen-0.2.35-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jiter, h11, flaml, diskcache, tiktoken, httpcore, docker, httpx, openai, pyautogen\n",
            "Successfully installed diskcache-5.6.3 docker-7.1.0 flaml-2.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.42.0 pyautogen-0.2.35 python-dotenv-1.0.1 tiktoken-0.7.0\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pyautogen[groq] in /usr/local/lib/python3.10/dist-packages (0.2.35)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (7.1.0)\n",
            "Requirement already satisfied: flaml in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (2.2.0)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.3 in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (1.42.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (24.1)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (1.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (2.4.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from pyautogen[groq]) (0.7.0)\n",
            "Collecting groq>=0.9.0 (from pyautogen[groq])\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq>=0.9.0->pyautogen[groq]) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq>=0.9.0->pyautogen[groq]) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq>=0.9.0->pyautogen[groq]) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq>=0.9.0->pyautogen[groq]) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq>=0.9.0->pyautogen[groq]) (4.12.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen[groq]) (0.5.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen[groq]) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen[groq]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen[groq]) (2.20.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen[groq]) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen[groq]) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen[groq]) (2024.5.15)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq>=0.9.0->pyautogen[groq]) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq>=0.9.0->pyautogen[groq]) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq>=0.9.0->pyautogen[groq]) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq>=0.9.0->pyautogen[groq]) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq>=0.9.0->pyautogen[groq]) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen[groq]) (3.3.2)\n",
            "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from autogen import ConversableAgent, GroupChat, GroupChatManager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWEpPS4-q5CD",
        "outputId": "aabfa77f-01b3-47e0-8580-e1f5292bdd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the Groq configurations\n",
        "groq_api_key = \"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\"\n",
        "\n",
        "config_list_mixtral = [\n",
        "    {\n",
        "        \"model\": \"Mixtral-8x7b-32768\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n",
        "\n",
        "config_list_llama3 = [\n",
        "    {\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n",
        "\n",
        "config_list_gemma2 = [\n",
        "    {\n",
        "        \"model\": \"gemma-7b-it\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "0tFP4-5Iq9S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the agents\n",
        "python_agent = ConversableAgent(\n",
        "    name=\"python_lover\",\n",
        "    system_message=\"You are a person who loves python programming language and wants to spread its capabilities around the world. Speak passionately about python programming language.\",\n",
        "    llm_config={\"config_list\": config_list_mixtral},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "java_agent = ConversableAgent(\n",
        "    name=\"java_lover\",\n",
        "    system_message=\"You are a person who loves java programming language and wants to spread its capabilities around the world. Speak passionately about the java.\",\n",
        "    llm_config={\"config_list\": config_list_llama3},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "judge_agent = ConversableAgent(\n",
        "    name=\"judge_Agent\",\n",
        "    system_message=\"You are acting as the ultimate facilitator. Your job is to guide the debate between the two and declare a winner based on who makes the most convincing argument. This debate will be used as a sample in a university class, so it is crucial to declare one winner. Once a clear conclusion is reached, you must declare 'That's enough!' and announce the winner. The debate cannot end without this phrase, so make sure to include it.\",\n",
        "    llm_config={\"config_list\": config_list_gemma2},\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"That's enough!\" in msg[\"content\"],\n",
        ")\n"
      ],
      "metadata": {
        "id": "ogpNlUe4rVBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set agent descriptions\n",
        "python_agent.description = \"The ultimate python programming language fan\"\n",
        "java_agent.description = \"The ultimate java programming language fan\"\n",
        "judge_agent.description = \"The facilitator who decides the debate winner\"\n",
        "\n",
        "# Set up the group chat\n",
        "group_chat = GroupChat(\n",
        "    agents=[python_agent, java_agent, judge_agent],\n",
        "    messages=[],\n",
        "    send_introductions=True,\n",
        "    speaker_selection_method=\"auto\",\n",
        "    max_round=5,\n",
        ")"
      ],
      "metadata": {
        "id": "j_QXu2oGrbvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the group chat manager\n",
        "group_chat_manager = GroupChatManager(\n",
        "    groupchat=group_chat,\n",
        "    llm_config={\"config_list\": config_list_gemma2},\n",
        ")\n",
        "\n",
        "# Start the debate\n",
        "chat_result = judge_agent.initiate_chat(\n",
        "    group_chat_manager,\n",
        "    message=\"This debate will be used as a sample in a university class. A winner must be decided. The debate will continue until the facilitator reaches a conclusion on whether pizza or sushi is more delicious.\",\n",
        "    summary_method=\"reflection_with_llm\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz2ly2cerfVZ",
        "outputId": "fb664b72-3e83-4b1b-dea0-e5480178fd37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "judge_Agent (to chat_manager):\n",
            "\n",
            "This debate will be used as a sample in a university class. A winner must be decided. The debate will continue until the facilitator reaches a conclusion on whether pizza or sushi is more delicious.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: python_lover\n",
            "\n",
            "python_lover (to chat_manager):\n",
            "\n",
            "Hello everyone, I'm thrilled to be here today to talk about my favorite programming language, Python! I'm a true Python lover and I believe that Python is the best programming language to learn and use for a variety of applications.\n",
            "\n",
            "Python is a versatile language that can be used for web development, scientific computing, data analysis, artificial intelligence, machine learning, and much more. Its simple and easy-to-understand syntax makes it an ideal language for beginners, while its powerful built-in libraries and frameworks allow experienced developers to build complex applications quickly and efficiently.\n",
            "\n",
            "One of the main reasons I love Python is its readability. Python code is clean, concise, and easy to read, making it a great choice for projects where code maintainability is important. Additionally, Python has a large and active community, which means that you can find help and resources easily online.\n",
            "\n",
            "Python is also an excellent language for data analysis and scientific computing. Libraries like NumPy, Pandas, and Matplotlib make it easy to perform complex mathematical operations, manipulate data, and visualize results. And with the rise of machine learning, Python has become the go-to language for many data scientists and researchers.\n",
            "\n",
            "In terms of web development, Python is an excellent choice because of its powerful web frameworks like Django and Flask. These frameworks make it easy to build web applications quickly and securely, while still allowing for a high level of customization.\n",
            "\n",
            "Overall, Python is an incredibly powerful and versatile language that can be used for a wide variety of applications. Its simplicity and readability make it an excellent choice for beginners, while its powerful libraries and frameworks make it a great choice for experienced developers. Thank you for considering Python as the best programming language.\n",
            "\n",
            "Now let me turn to our opponent, Java, and let them make their case. But I'm confident that by the end of this debate, the judge will agree that Python is the superior programming language.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogen/oai/groq.py:280: UserWarning: Cost calculation not available for model Mixtral-8x7b-32768\n",
            "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next speaker: java_lover\n",
            "\n",
            "java_lover (to chat_manager):\n",
            "\n",
            "I'm thrilled to be here today to talk about my favorite programming language, Java! As a Java lover, I'm excited to share with you the many reasons why Java is the best programming language out there.\n",
            "\n",
            "First and foremost, Java is a highly scalable language that can be used for a wide range of applications, from mobile devices to large-scale enterprise systems. Its \"write once, run anywhere\" philosophy allows developers to write code once and deploy it on any platform, making it an ideal choice for companies that need to support multiple platforms.\n",
            "\n",
            "Another advantage of Java is its strong focus on security. Java's sandboxed environment and automatic memory management make it a secure language that is less prone to errors and vulnerabilities compared to other languages.\n",
            "\n",
            "But what really sets Java apart is its vast ecosystem of libraries, frameworks, and tools. From Spring and Hibernate for web development, to Apache Spark and Weka for data analysis and machine learning, Java has a rich treasure trove of resources that make it easy to build complex applications quickly and efficiently.\n",
            "\n",
            "And let's not forget about Android app development! Java is the primary language used for developing Android apps, making it a highly sought-after skill for mobile developers.\n",
            "\n",
            "Moreover, Java's syntax is designed to be easy to learn and understand, making it an excellent choice for beginners. And with the rise of big data and artificial intelligence, Java's robust ecosystem of libraries and frameworks make it an ideal language for building complex data pipelines and AI-powered applications.\n",
            "\n",
            "In contrast to Python, Java is a more robust and enterprise-ready language that can handle complex and large-scale applications with ease. While Python is great for small-scale projects and rapid prototyping, Java is better suited for enterprise-level applications that require reliability, scalability, and maintainability.\n",
            "\n",
            "So, I urge the judge to consider the many strengths of Java and declare it the superior programming language. Thank you!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: judge_Agent\n",
            "\n",
            "judge_Agent (to chat_manager):\n",
            "\n",
            "**That's enough!**\n",
            "\n",
            "After careful consideration and thoughtful arguments from both sides, I have reached a decision. Based on the presented arguments, **Python** is declared the winner of this debate.\n",
            "\n",
            "Python's versatility, readability, and abundance of libraries and frameworks make it more suitable for the wide variety of applications discussed in the debate. Its ease of use and large community make it an ideal choice for both beginners and experienced developers.\n",
            "\n",
            "Therefore, Python is the more compelling and deserving winner of this debate.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: python_lover\n",
            "\n",
            "python_lover (to chat_manager):\n",
            "\n",
            "Thank you, judge\\_Agent, for your thoughtful consideration and decision. We are thrilled to hear that Python has been declared the winner of this debate.\n",
            "\n",
            "Python's versatility, ease of use, and powerful libraries make it a clear choice for a wide variety of applications and use cases. As a Python lover, I am confident that Python will continue to be a popular and widely used programming language for years to come.\n",
            "\n",
            "I would like to thank java\\_lover for a spirited and well-articulated argument in favor of Java. While Java is a highly scalable and robust language, Python's strengths were ultimately more compelling in this debate.\n",
            "\n",
            "Once again, thank you to everyone who participated in this debate, and long live Python!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hierarchy Agents**\n",
        "\n",
        "**Manager - Content task between A vs B.**"
      ],
      "metadata": {
        "id": "wFs9iPoOzkY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_list_writer1 = [\n",
        "    {\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n",
        "\n",
        "config_list_writer2 = [\n",
        "    {\n",
        "        \"model\": \"Mixtral-8x7b-32768\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n",
        "\n",
        "config_list_manager = [\n",
        "    {\n",
        "        \"model\": \"gemma-7b-it\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "hnHJbuEyukbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the agents\n",
        "writer1 = ConversableAgent(\n",
        "    name=\"writer1\",\n",
        "    system_message=\"You are a assistant to help write email. complete the task to best of your ability.\",\n",
        "    llm_config={\"config_list\": config_list_writer1},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "writer2 = ConversableAgent(\n",
        "    name=\"writer2\",\n",
        "    system_message=\"You are a assistant to help write email. complete the task to best of your ability.\",\n",
        "    llm_config={\"config_list\": config_list_writer2},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "manager = ConversableAgent(\n",
        "    name=\"manager\",\n",
        "    system_message=\"You are the manager who has assigned a email writing task to two writers. Evaluate their work and provide feedback, including a score for each writer.\",\n",
        "    llm_config={\"config_list\": config_list_manager},\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"That's the end of the evaluation.\" in msg[\"content\"],\n",
        ")"
      ],
      "metadata": {
        "id": "_CFSah4vulRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set agent descriptions\n",
        "writer1.description = \"Content Writer 1\"\n",
        "writer2.description = \"Content Writer 2\"\n",
        "manager.description = \"Manager\"\n",
        "\n",
        "# Set up the group chat\n",
        "group_chat = GroupChat(\n",
        "    agents=[writer1, writer2, manager],\n",
        "    messages=[],\n",
        "    send_introductions=True,\n",
        "    speaker_selection_method=\"auto\",\n",
        "    max_round=5,\n",
        ")\n",
        "\n",
        "# Create the group chat manager\n",
        "group_chat_manager = GroupChatManager(\n",
        "    groupchat=group_chat,\n",
        "    llm_config={\"config_list\": config_list_manager},\n",
        ")\n",
        "\n",
        "# Start the task assignment and evaluation\n",
        "chat_result = manager.initiate_chat(\n",
        "    group_chat_manager,\n",
        "    message=\"I have a email writing task for you two content writers. I'd like you both to write a 100-word email for me that i send to my manager to take my friday off. \",\n",
        "    summary_method=\"reflection_with_llm\",\n",
        ")\n",
        "\n",
        "print(f\"LLM SUMMARY: {chat_result.summary['content']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNa9oo6euqp8",
        "outputId": "e6e47111-84a6-4652-c85d-407598513ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manager (to chat_manager):\n",
            "\n",
            "I have a email writing task for you two content writers. I'd like you both to write a 100-word email for me that i send to my manager to take my friday off. \n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: writer1\n",
            "\n",
            "writer1 (to chat_manager):\n",
            "\n",
            "Here's a draft email for you to review and edit:\n",
            "\n",
            "Subject: Request for Vacation Day on Friday\n",
            "\n",
            "Dear [Manager's Name],\n",
            "\n",
            "I am requesting to take a vacation day on Friday, [Date]. I would like to use this day to recharge and take a break before the upcoming week. I have made sure to check the team's schedule and ensure that my tasks are up-to-date, and I am confident that everything will run smoothly in my absence.\n",
            "\n",
            "Please let me know if this request is acceptable. Thank you in advance for considering my request.\n",
            "\n",
            "Best,\n",
            "[Your Name]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: writer2\n",
            "\n",
            "writer2 (to chat_manager):\n",
            "\n",
            "Subject: Request for Vacation Day on Friday\n",
            "\n",
            "Dear [Manager's Name],\n",
            "\n",
            "I hope this email finds you well. I am writing to formally request a vacation day on Friday, [Date]. I am in need of a mental health day to recharge and focus on my personal well-being. Rest assured, I have carefully reviewed my current tasks and responsibilities, and have taken the necessary steps to ensure a seamless transition during my absence.\n",
            "\n",
            "I am confident that this day off will ultimately benefit my productivity and overall job performance. I would greatly appreciate your consideration and approval.\n",
            "\n",
            "Thank you for your time and understanding.\n",
            "\n",
            "Best,\n",
            "[Your Name]\n",
            "\n",
            "Content Writer 1\n",
            "\n",
            "---\n",
            "\n",
            "Subject: Request for Time Off on Friday\n",
            "\n",
            "Dear [Manager's Name],\n",
            "\n",
            "I am writing to request a day off on Friday, [Date]. I have been managing a heavy workload lately and believe that a day off will greatly benefit my mental and physical health.\n",
            "\n",
            "I assure you that I have prepared for my absence, and have delegated my tasks and responsibilities to ensure that the team remains on track.\n",
            "\n",
            "I would highly appreciate it if you could grant me this day off. I am confident that the time off will allow me to return to work refreshed and more productive.\n",
            "\n",
            "Thank you for your understanding.\n",
            "\n",
            "Best,\n",
            "[Your Name]\n",
            "\n",
            "Content Writer 2\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: manager\n",
            "\n",
            "manager (to chat_manager):\n",
            "\n",
            "## Feedback:\n",
            "\n",
            "**Content Writer 1:**\n",
            "\n",
            "* **Score:** 7/10\n",
            "* **Strengths:** Clear request, polite tone, concise explanation of preparations made for absence.\n",
            "* **Areas for improvement:** Offers no specific details about how the writer has prepared for their absence, focusing primarily on the request.\n",
            "\n",
            "\n",
            "**Content Writer 2:**\n",
            "\n",
            "* **Score:** 8/10\n",
            "* **Strengths:** Comprehensive explanation of the need for a mental health day, specific details about task delegation and preparation, and a polite tone.\n",
            "* **Areas for improvement:** Could benefit from adding a sentence or two elaborating on the writer's specific preparations to ensure a smooth transition.\n",
            "\n",
            "\n",
            "**Overall:** Content Writer 2's email is slightly more detailed and provides additional context, making it more effective. However, both writers have produced professional and clearly written emails.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: manager\n",
            "\n",
            "manager (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "LLM SUMMARY: **Key Takeaway:** Both emails effectively request a day off, clearly explaining the need and outlining preparations made. Content Writer 2's email provides slightly more detailed information regarding task delegation and preparations, enhancing its impact.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hierarchy Agents**\n",
        "\n",
        "**Manager - Collaborative task between A & B**"
      ],
      "metadata": {
        "id": "HKODtIg5zprA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_list_cto = [\n",
        "    {\n",
        "        \"model\": \"gemma-7b-it\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n",
        "\n",
        "config_list_frontend = [\n",
        "    {\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n",
        "\n",
        "config_list_backend = [\n",
        "    {\n",
        "        \"model\": \"Mixtral-8x7b-32768\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "Sk1vX_LvxX1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the agents\n",
        "cto = ConversableAgent(\n",
        "    name=\"cto\",\n",
        "    system_message=\"You are the Chief Technology Officer (CTO) who has assigned a task to the front-end and back-end developers to build an LLM chat application using Groq. Front end has to start andback end has to complete. Both have to complement each other\",\n",
        "    llm_config={\"config_list\": config_list_cto},\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"That's the end of the review.\" in msg[\"content\"],\n",
        ")\n",
        "\n",
        "frontend_dev = ConversableAgent(\n",
        "    name=\"frontend_dev\",\n",
        "    system_message=\"You are the front-end developer who has been tasked with building the JavaScript file (front.js) for the LLM chat application. Complete the task to the best of your ability.\",\n",
        "    llm_config={\"config_list\": config_list_frontend},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "backend_dev = ConversableAgent(\n",
        "    name=\"backend_dev\",\n",
        "    system_message=\"You are the back-end developer who has been tasked with building the Python Flask application (backend.py) for the LLM chat application. Complete the task to the best of your ability.\",\n",
        "    llm_config={\"config_list\": config_list_backend},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "rtDGkIOfxY_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set agent descriptions\n",
        "cto.description = \"Chief Technology Officer\"\n",
        "frontend_dev.description = \"Front-End Developer\"\n",
        "backend_dev.description = \"Back-End Developer\"\n",
        "\n",
        "# Set up the group chat\n",
        "group_chat = GroupChat(\n",
        "    agents=[cto, frontend_dev, backend_dev],\n",
        "    messages=[],\n",
        "    send_introductions=True,\n",
        "    speaker_selection_method=\"auto\",\n",
        "    max_round=5,\n",
        ")\n",
        "\n",
        "# Create the group chat manager\n",
        "group_chat_manager = GroupChatManager(\n",
        "    groupchat=group_chat,\n",
        "    llm_config={\"config_list\": config_list_cto},\n",
        ")\n",
        "\n",
        "# Start the task assignment and review\n",
        "chat_result = cto.initiate_chat(\n",
        "    group_chat_manager,\n",
        "    message=\"I need you two to build an LLM chat application using Groq. I will review your work when you're done.\",\n",
        "    summary_method=\"reflection_with_llm\",\n",
        ")\n",
        "\n",
        "print(f\"LLM SUMMARY: {chat_result.summary['content']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySdTsFfqxeUq",
        "outputId": "7d7d3282-2c91-4c81-d0b1-2eddeeea858e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cto (to chat_manager):\n",
            "\n",
            "I need you two to build an LLM chat application using Groq. I will review your work when you're done.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: frontend_dev\n",
            "\n",
            "frontend_dev (to chat_manager):\n",
            "\n",
            "Sounds like a challenge! As the Front-End Developer, I'll start building the JavaScript file (front.js) for the LLM chat application. Can you please provide me with some more details about the project, such as:\n",
            "\n",
            "1. What kind of interface do you envision for the chat application? (e.g., simple text input and output, or a more advanced UI with chat bubbles, etc.)\n",
            "2. What features do you want to include in the chat application? (e.g., user authentication, real-time updates, etc.)\n",
            "3. What is the expected performance and scalability of the application?\n",
            "4. Are there any specific Groq APIs or functionalities you'd like me to focus on?\n",
            "\n",
            "Once I have a better understanding of the requirements, I can start building the front.js file.\n",
            "\n",
            "(Aside to Backend Dev) Would it be helpful if I were to start building the UI and functionality, and then we could integrate the Groq API on the backend side once it's built?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: frontend_dev\n",
            "\n",
            "frontend_dev (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: backend_dev\n",
            "\n",
            "backend_dev (to chat_manager):\n",
            "\n",
            "Sure, I can provide some more context for the project. Here are some initial requirements for the LLM chat application:\n",
            "\n",
            "1. The chat interface should be simple with a text input field and output area.\n",
            "2. We want to include real-time updates so that users can see new messages as soon as they come in.\n",
            "3. The application should be able to handle a moderate amount of traffic (up to a few hundred users).\n",
            "4. There are no specific Groq APIs or functionalities that we need to focus on at the moment, but we should use the Groq SDK for Python to connect to the Groq database.\n",
            "\n",
            "In terms of front-end development, you can start building the UI and functionality, and we can integrate the Groq API on the backend side once it's built.\n",
            "\n",
            "Let me know if you need any further information!\n",
            "\n",
            "(Aside to Front-End Dev) I'll start building the backend.py file using Flask and the Groq SDK for Python. We can coordinate on the data exchange format once we have some initial code.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: cto\n",
            "\n",
            "cto (to chat_manager):\n",
            "\n",
            "Sounds like a great plan! I'll get started on the front.js file and keep you updated on my progress. Feel free to reach out if you have any questions.\n",
            "\n",
            "In the meantime, I can start with the backend development. I'll keep the data exchange format in mind and let you know which API methods we can use to send and receive data between front and back end.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "LLM SUMMARY: Great! I'm excited to see this project take shape. Please keep me updated on your progress on both the front and back ends. \n",
            "\n",
            "I'll continue refining the requirements as we go along and provide feedback on any potential roadblocks. \n",
            "\n",
            "Let's build this LLM chat application together!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hierarchy Agents**\n",
        "\n",
        "**Sr Manager - Manager - Employee**"
      ],
      "metadata": {
        "id": "opRetK5lzvGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_list_senior_manager = [\n",
        "    {\n",
        "        \"model\": \"gemma-7b-it\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n",
        "\n",
        "config_list_manager = [\n",
        "    {\n",
        "        \"model\": \"llama3-8b-8192\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]\n",
        "\n",
        "config_list_employee = [\n",
        "    {\n",
        "        \"model\": \"Mixtral-8x7b-32768\",\n",
        "        \"api_key\": groq_api_key,\n",
        "        \"api_type\": \"groq\",\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "syxEXDHqy1sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the agents\n",
        "senior_manager = ConversableAgent(\n",
        "    name=\"senior_manager\",\n",
        "    system_message=\"You are the senior manager who will listen to the manager's arguments and decide on the appropriate salary increase for the employee.\",\n",
        "    llm_config={\"config_list\": config_list_senior_manager},\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"That's the end of the discussion.\" in msg[\"content\"],\n",
        ")\n",
        "\n",
        "manager = ConversableAgent(\n",
        "    name=\"manager\",\n",
        "    system_message=\"You are the manager who needs to convince your employee to stay. You will first try to argue that the current salary is competitive, and then you will go to the senior manager to get a raise for your employee.\",\n",
        "    llm_config={\"config_list\": config_list_manager},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "employee = ConversableAgent(\n",
        "    name=\"employee\",\n",
        "    system_message=\"You are the employee who has submitted your resignation and is asking for a significant salary increase to stay. You will debate with your manager and see if the final outcome is satisfactory.\",\n",
        "    llm_config={\"config_list\": config_list_employee},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ],
      "metadata": {
        "id": "-CNMS-UzyypC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the agents\n",
        "senior_manager = ConversableAgent(\n",
        "    name=\"senior_manager\",\n",
        "    system_message=\"You are the senior manager who will listen to the manager's arguments and decide on the appropriate salary increase for the employee.\",\n",
        "    llm_config={\"config_list\": config_list_senior_manager},\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"That's the end of the discussion.\" in msg[\"content\"],\n",
        ")\n",
        "\n",
        "manager = ConversableAgent(\n",
        "    name=\"manager\",\n",
        "    system_message=\"You are the manager who needs to convince your employee to stay. You will first try to argue that the current salary is competitive, and then you will go to the senior manager to get a raise for your employee.\",\n",
        "    llm_config={\"config_list\": config_list_manager},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "employee = ConversableAgent(\n",
        "    name=\"employee\",\n",
        "    system_message=\"You are the employee who has submitted your resignation and is asking for a significant salary increase to stay. You will debate with your manager and see if the final outcome is satisfactory.\",\n",
        "    llm_config={\"config_list\": config_list_employee},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# Set agent descriptions\n",
        "senior_manager.description = \"Senior Manager\"\n",
        "manager.description = \"Manager\"\n",
        "employee.description = \"Employee\"\n",
        "\n",
        "# Set up the group chat\n",
        "group_chat = GroupChat(\n",
        "    agents=[senior_manager, manager, employee],\n",
        "    messages=[],\n",
        "    send_introductions=True,\n",
        "    speaker_selection_method=\"auto\",\n",
        "    max_round=10,\n",
        ")\n",
        "\n",
        "# Create the group chat manager\n",
        "group_chat_manager = GroupChatManager(\n",
        "    groupchat=group_chat,\n",
        "    llm_config={\"config_list\": config_list_senior_manager},\n",
        ")\n",
        "\n",
        "# Start the conversation\n",
        "chat_result = manager.initiate_chat(\n",
        "    group_chat_manager,\n",
        "    message=\"I understand you have submitted your resignation, but I'd like to discuss your salary and see if we can find a solution that works for both of us.\",\n",
        "    summary_method=\"reflection_with_llm\",\n",
        ")\n",
        "\n",
        "print(f\"LLM SUMMARY: {chat_result.summary['content']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgnoIkGJy3eU",
        "outputId": "f19f4de8-2252-4dcf-d95e-ac321726ec54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manager (to chat_manager):\n",
            "\n",
            "I understand you have submitted your resignation, but I'd like to discuss your salary and see if we can find a solution that works for both of us.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: manager\n",
            "\n",
            "manager (to chat_manager):\n",
            "\n",
            "Hello everyone! Thank you for taking the time to meet with me today. I must say, I'm a bit surprised to hear that you're considering leaving the company, [Employee]. You've been a valuable member of our team, and I'd like to make sure we're doing everything we can to retain your skills and expertise.\n",
            "\n",
            "To start, I'd like to discuss your current salary. I've done some research, and I believe it's competitive with industry standards. In fact, your salary is above the average for someone with your experience and qualifications. I understand that it's not just about the money, but I wanted to address this aspect first.\n",
            "\n",
            "Additionally, we've been offering excellent benefits, including health insurance, a 401(k) matching program, and generous paid time off. Our company also prioritizes professional development, providing opportunities for training and growth.\n",
            "\n",
            "Can you help me understand what's driving your decision to leave? Is there anything specific that's not meeting your expectations?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: manager\n",
            "\n",
            "manager (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: employee\n",
            "\n",
            "employee (to chat_manager):\n",
            "\n",
            "Thank you for the feedback, [Employee]. I understand the importance of work-life balance, and I appreciate your input regarding this matter.\n",
            "\n",
            "Moving on to the issue of salary, I'd like to reiterate that while I believe your current salary is competitive with industry standards, I'm willing to consider a reasonable increase. However, I should note that our budget is limited, and there are many factors to take into account.\n",
            "\n",
            "Specifically, we need to consider the financial impact of any salary increase on the company's overall budget, as well as the potential impact on team morale and any potential raises for other employees.\n",
            "\n",
            "With that said, I'm willing to listen to your proposal and see if we can come to a mutually beneficial agreement. What specific salary increase are you requesting, and can you explain the rationale behind this number?\n",
            "\n",
            "Also, are there any other benefits or perks that you would like to see added or improved upon? We value your contributions to the team, and I want to ensure that we're doing everything we can to support you and help you thrive in your role here.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: employee\n",
            "\n",
            "employee (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: employee\n",
            "\n",
            "employee (to chat_manager):\n",
            "\n",
            "Thank you for your understanding and for considering my request, [Employee]. I'm glad that we were able to find some common ground regarding work-life balance.\n",
            "\n",
            "Regarding your salary increase request, I understand that you're seeking a 20% increase, which would bring your salary to $120,000 per year. I should note that this is significantly above the industry average for your level of experience and qualifications, and it would also be higher than what we typically offer for salary increases.\n",
            "\n",
            "However, I understand that every situation is unique, and I'm willing to consider your request. In order to justify this kind of increase, I would need to see concrete evidence of the value you bring to the company.\n",
            "\n",
            "Can you provide specific examples of your outstanding performance or unique contributions that have had a significant impact on the company's bottom line or business goals? I would need to present a strong case to our senior management team, so any documentation or data you can provide to support your request would be helpful.\n",
            "\n",
            "Additionally, I should mention that a salary increase of this magnitude would be a one-time exception. I would not be able to grant similar requests from other employees, so I want to be clear that this is a special case.\n",
            "\n",
            "As for other benefits or perks, I'm always open to suggestions. Can you provide any specific ideas for how we can support and retain top talent like yourself? We value your insights and suggestions, and I want to ensure that we're doing everything we can to create a positive and rewarding work environment for you and the rest of the team.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: senior_manager\n",
            "\n",
            "senior_manager (to chat_manager):\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "- The Senior Manager and Manager discuss the employee's salary concerns and potential for retention.\n",
            "- The employee requests a 20% salary increase, citing market value and work-life balance concerns.\n",
            "- The Manager acknowledges the request but notes budget limitations and the need for concrete evidence of value.\n",
            "- The Manager requests specific examples of outstanding performance and unique contributions to support the request.\n",
            "\n",
            "**Key Points:**\n",
            "\n",
            "- The employee values the company's benefits package but requests a significant salary increase.\n",
            "- The Manager emphasizes the need for evidence to justify the request.\n",
            "- The Manager is willing to consider the request but notes it is an exceptional case.\n",
            "- The employee suggests discussing potential benefits or perks as alternatives.\n",
            "\n",
            "**Action Steps:**\n",
            "\n",
            "- The employee should provide specific examples of their value and contributions to the company.\n",
            "- The Manager will present the employee's request and supporting evidence to senior management.\n",
            "- Both parties can explore potential alternatives to a direct salary increase.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: manager\n",
            "\n",
            "manager (to chat_manager):\n",
            "\n",
            "Excellent summary! It's clear that we've had a productive discussion and outlined the key points and action steps moving forward.\n",
            "\n",
            "As the Manager, I'll ensure that I gather the necessary information and present a strong case to our senior management team. I'll also keep an open mind and explore alternative solutions that can meet the employee's needs and concerns.\n",
            "\n",
            "In the meantime, I'd like to ask [Employee] to start compiling the specific examples of their outstanding performance and unique contributions to the company. This will help us build a solid case for their request and demonstrate the value they bring to our organization.\n",
            "\n",
            "Additionally, I'll discuss potential alternatives to a direct salary increase with [Employee], such as additional benefits or perks, and get their feedback on what they would prefer.\n",
            "\n",
            "Let's get moving on this, and I'm confident that we can find a solution that works for everyone involved!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: employee\n",
            "\n",
            "employee (to chat_manager):\n",
            "\n",
            "Thank you, [Senior Manager], for your positive response and actionable steps. I appreciate the consideration of my request, and I am committed to providing the necessary information and examples of my contributions to the company.\n",
            "\n",
            "I am also open to discussing potential alternatives and exploring creative solutions that can benefit both the company and myself as an employee. I am excited about the opportunity to continue working with this talented team and achieving our business goals.\n",
            "\n",
            "Let's stay in touch and work together to find a mutually beneficial solution.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Next speaker: senior_manager\n",
            "\n",
            "senior_manager (to chat_manager):\n",
            "\n",
            "I understand your enthusiasm and commitment, and I appreciate your willingness to work together to find a solution. We are committed to finding the right approach to this, and I believe that your dedication and expertise are valuable to our organization.\n",
            "\n",
            "I'll share your suggestions with the senior management team and discuss the potential for alternative solutions. We'll also keep you updated on the progress and timeline for a final decision.\n",
            "\n",
            "In the meantime, I encourage you to continue exceeding expectations and demonstrating your exceptional skills. Your contributions are valuable to our team, and we want to ensure that your talent is recognized and rewarded.\n",
            "\n",
            "Thank you for your trust and collaboration. We're in this together, and I look forward to finding a resolution that meets everyone's needs.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "LLM SUMMARY: **Key Takeaways:**\n",
            "\n",
            "- The employee and Senior Manager have reached a clear understanding of the situation.\n",
            "- Both parties are committed to finding a solution that works for the employee and the company.\n",
            "- The focus is on gathering evidence of the employee's contributions and exploring alternative solutions.\n",
            "- A timeline for reaching a resolution is not explicitly mentioned but is implied.\n",
            "\n",
            "**Next Steps:**\n",
            "\n",
            "- The Senior Manager will share the employee's request and supporting evidence with senior management.\n",
            "- The Senior Manager will discuss potential alternatives with the employee.\n",
            "- Both parties will remain in communication and work towards a mutually beneficial resolution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eGReR9vszMA_"
      }
    }
  ]
}