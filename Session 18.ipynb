{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Load dependencies and libraries\n",
        "!pip install llama-index ragstack-ai pdfplumber transformers optimum[exporters] llama-index-llms-groq llama-index-embeddings-huggingface-optimum\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "import pdfplumber\n",
        "from llama_index.core import Document, StorageContext, VectorStoreIndex, SimpleDirectoryReader, Settings\n",
        "from llama_index.vector_stores.astra_db import AstraDBVectorStore\n",
        "from llama_index.embeddings.huggingface_optimum import OptimumEmbedding\n",
        "from llama_index.llms.groq import Groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDKtZ5352W5q",
        "outputId": "ec6dcfc3-2d41-4e93-ac43-a04bd43f39a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.10.31)\n",
            "Requirement already satisfied: ragstack-ai in /usr/local/lib/python3.10/dist-packages (1.0.7)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: llama-index-llms-groq in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface-optimum in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
            "Requirement already satisfied: optimum[exporters] in /usr/local/lib/python3.10/dist-packages (1.21.2)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.9)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.13)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.31 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.10.59)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.11)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.27)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.8)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.7)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.32)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: ragstack-ai-colbert==1.0.5 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai) (1.0.5)\n",
            "Requirement already satisfied: ragstack-ai-langchain==1.0.7 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.0.7)\n",
            "Requirement already satisfied: ragstack-ai-llamaindex==1.0.5 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.0.5)\n",
            "Requirement already satisfied: cassio<0.2.0,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-colbert==1.0.5->ragstack-ai) (0.1.8)\n",
            "Requirement already satisfied: colbert-ai==0.2.19 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-colbert==1.0.5->ragstack-ai) (0.2.19)\n",
            "Requirement already satisfied: pyarrow==14.0.1 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-colbert==1.0.5->ragstack-ai) (14.0.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-colbert==1.0.5->ragstack-ai) (2.8.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-colbert==1.0.5->ragstack-ai) (2.2.1)\n",
            "Requirement already satisfied: astrapy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.4.1)\n",
            "Requirement already satisfied: langchain==0.1.19 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.1.19)\n",
            "Requirement already satisfied: langchain-astradb==0.3.3 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.3.3)\n",
            "Requirement already satisfied: langchain-community==0.0.38 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.0.38)\n",
            "Requirement already satisfied: langchain-core==0.1.52 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.1.52)\n",
            "Requirement already satisfied: langchain-openai==0.1.3 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.1.3)\n",
            "Requirement already satisfied: unstructured==0.14.2 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.14.2)\n",
            "Requirement already satisfied: langchain-google-genai==0.0.11 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.0.11)\n",
            "Requirement already satisfied: langchain-google-vertexai==1.0.1 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.0.1)\n",
            "Requirement already satisfied: langchain-nvidia-ai-endpoints==0.0.9 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.0.9)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex==1.0.5->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.16.0)\n",
            "Requirement already satisfied: llama-index-embeddings-langchain==0.1.2 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex==1.0.5->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.2)\n",
            "Requirement already satisfied: llama-index-tools-cassandra==0.1.1 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex==1.0.5->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.1)\n",
            "Requirement already satisfied: llama-index-vector-stores-astra-db==0.1.7 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex==1.0.5->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.7)\n",
            "Requirement already satisfied: llama-index-vector-stores-cassandra==0.1.3 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex==1.0.5->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.3)\n",
            "Requirement already satisfied: llama-parse==0.4.1 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex==1.0.5->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.4.1)\n",
            "Requirement already satisfied: llama-index-embeddings-azure-openai==0.1.7 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.7)\n",
            "Requirement already satisfied: llama-index-llms-azure-openai==0.1.6 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.6)\n",
            "Requirement already satisfied: llama-index-embeddings-gemini==0.1.6 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.6)\n",
            "Requirement already satisfied: llama-index-llms-gemini==0.1.7 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.7)\n",
            "Requirement already satisfied: llama-index-llms-vertex==0.1.5 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.5)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-gemini==0.1.5 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.5)\n",
            "Requirement already satisfied: llama-index-embeddings-bedrock==0.1.4 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.4)\n",
            "Requirement already satisfied: llama-index-llms-bedrock==0.1.7 in /usr/local/lib/python3.10/dist-packages (from ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.7)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.9.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.19.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.2.5)\n",
            "Requirement already satisfied: git-python in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (1.0.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (1.0.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (1.11.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (4.66.4)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (5.10.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.6.7)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.1.96)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.1.52->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core==0.1.52->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (23.2)\n",
            "Requirement already satisfied: google-generativeai<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai==0.0.11->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.47.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.59.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.18.0)\n",
            "Requirement already satisfied: types-protobuf<5.0.0.0,>=4.24.0.4 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (4.25.0.20240417)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.32.0.20240712)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain-nvidia-ai-endpoints==0.0.9->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (10.4.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.3->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.39.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.3->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.7.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.23 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-bedrock==0.1.4->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.34.153)\n",
            "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.17.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.27.0)\n",
            "Requirement already satisfied: llama-index-llms-anthropic<0.2.0,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-bedrock==0.1.7->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.1.16)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.2.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.12.1)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (3.9.5)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.2.1)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.25.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.16.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (12.6.20)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum[exporters]) (15.0.1)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from optimum[exporters]) (1.16.2)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from optimum[exporters]) (1.18.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from optimum[exporters]) (1.0.8)\n",
            "Requirement already satisfied: llama-index-llms-openai-like<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-groq) (0.1.3)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface-optimum) (0.1.5)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.31->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.31->llama-index) (1.0.8)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.31->llama-index) (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.31->llama-index) (2.1.4)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.31->llama-index) (0.9.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.19 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2->llama-index) (0.1.19)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2024.7.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum[exporters]) (3.20.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum[exporters]) (0.1.99)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum[exporters]) (10.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.70.16)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->optimum[exporters]) (24.3.25)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->optimum[exporters]) (0.17.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.9.4)\n",
            "Requirement already satisfied: deprecation<2.2.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from astrapy<2,>=1->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.1.0)\n",
            "Requirement already satisfied: pymongo>=3 in /usr/local/lib/python3.10/dist-packages (from astrapy<2,>=1->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (4.8.0)\n",
            "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from astrapy<2,>=1->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.10.2)\n",
            "Requirement already satisfied: uuid6<2024.2.0,>=2024.1.12 in /usr/local/lib/python3.10/dist-packages (from astrapy<2,>=1->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2024.1.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.5)\n",
            "Requirement already satisfied: cassandra-driver<4.0.0,>=3.28.0 in /usr/local/lib/python3.10/dist-packages (from cassio<0.2.0,>=0.1.7->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.29.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.16.0->ragstack-ai-llamaindex==1.0.5->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (2.22)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (3.21.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.14.0)\n",
            "Requirement already satisfied: minijinja>=1.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (2.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.4.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.3->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.20.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.31->llama-index) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.31->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.31->llama-index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.31->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.2.2)\n",
            "Requirement already satisfied: azure-core>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.30.2)\n",
            "Requirement already satisfied: msal>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.30.0)\n",
            "Requirement already satisfied: msal-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.2.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.153 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.23->llama-index-embeddings-bedrock==0.1.4->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.34.153)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.23->llama-index-embeddings-bedrock==0.1.4->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.23->llama-index-embeddings-bedrock==0.1.4->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.10.2)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver<4.0.0,>=3.28.0->cassio<0.2.0,>=0.1.7->ragstack-ai-colbert==1.0.5->ragstack-ai) (0.2.1.post1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.19.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.24.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.12.4)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.0.5)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.7.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.5.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.4.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy<2,>=1->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (4.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.1.52->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (3.10.6)\n",
            "Requirement already satisfied: anthropic<0.29.0,>=0.26.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.7->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.28.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo>=3->astrapy<2,>=1->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.31->llama-index) (1.16.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->ragstack-ai-colbert==1.0.5->ragstack-ai) (2.1.5)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (from git-python->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (3.1.43)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (7.0.1)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.0.6)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.0.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.7->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (0.5.0)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured==0.14.2->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (4.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.63.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (4.9)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.13.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<2,>=1->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<2,>=1->ragstack-ai-langchain==1.0.7->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (4.0.0)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.24.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (2.8.0)\n",
            "Requirement already satisfied: portalocker<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from msal-extensions>=0.3.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.6->ragstack-ai-llamaindex[azure,bedrock,colbert,google]==1.0.5->ragstack-ai) (2.10.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython->git-python->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (4.0.11)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragstack-ai-colbert==1.0.5->ragstack-ai) (5.0.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai==1.0.1->ragstack-ai-langchain[colbert,google,nvidia]==1.0.7->ragstack-ai) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"ASTRA_DB_API_ENDPOINT\"] = \"https://7c7e7cda-bb99-491a-88a3-dd75d41c0b0d-us-east-2.apps.astra.datastax.com\"\n",
        "os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = \"AstraCS:PEZqYNpmWDhAynggLjtTvqpM:ad3b93fe4f7c9609ec21668984073da866093171657e4611f4ccc88602235bcf\"\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "DmTSESRv2b01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the cell 2 from previous code and paste in above cell"
      ],
      "metadata": {
        "id": "5zLISYgFablc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Groq(model=\"mixtral-8x7b-32768\")\n",
        "Settings.llm = llm\n"
      ],
      "metadata": {
        "id": "ugaQmQAP3ZlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load a PDF and extract text\n",
        "pdf_path = \"/content/agenda.pdf\"  # Replace with your actual PDF path\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# New function to chunk text\n",
        "def chunk_text(text, chunk_size=250):  # Reduced chunk size\n",
        "    \"\"\"Split text into smaller chunks of specified size.\"\"\"\n",
        "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "# Chunk the extracted PDF text\n",
        "text_chunks = chunk_text(pdf_text)\n",
        "\n",
        "# Check if we have enough chunks\n",
        "if len(text_chunks) < 10:\n",
        "    print(\"Warning: Not enough chunks created. Consider reducing the chunk size further or checking the PDF content.\")\n",
        "\n",
        "print(f\"Number of chunks created: {len(text_chunks)}\")\n",
        "for idx, chunk in enumerate(text_chunks):\n",
        "    print(f\"Chunk {idx + 1} ({len(chunk)} characters):\\n{chunk}\\n\")\n",
        "\n",
        "# Create Document objects for each chunk\n",
        "documents = [Document(text=chunk) for chunk in text_chunks]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTZasxPh3dV2",
        "outputId": "c026557d-d62e-4514-f454-47d790191386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks created: 36\n",
            "Chunk 1 (250 characters):\n",
            "Agenda\n",
            "Global IndiaAI Summit 2024 3-4 July 2024, New Delhi\n",
            "Day 1 - Wednesday, July 3\n",
            "Start Session Description\n",
            "10:00 - 11:00\n",
            "Opening Ceremony (Auditorium 1)\n",
            "11:00 – 13:30\n",
            "GPAI Session (@ Summit Room) : Executive Council Meeting\n",
            "(By Invitation only)\n",
            "1\n",
            "\n",
            "Chunk 2 (250 characters):\n",
            "1:30 - 13:00 Side Event 1 (@ The session is about learning and sharing knowledge on Large\n",
            "Auditorium 1): Language Models (LLMs) and Large Multimodal Models (LMMs),\n",
            "with the aim to understand the unique linguistic and cultural\n",
            "IndiaAI: Large diversity\n",
            "\n",
            "Chunk 3 (250 characters):\n",
            " inherent to India, examining how LLMs can effectively\n",
            "Language Model address challenges associated with multilingualism. Furthermore,\n",
            "the session will cover the ethical considerations and biases linked\n",
            "to these models, promoting a discussion on resp\n",
            "\n",
            "Chunk 4 (250 characters):\n",
            "onsible AI\n",
            "practices, including fairness, inclusiveness, misinformation\n",
            "mitigation, and intellectual property rights within diverse cultural\n",
            "contexts. Lastly, the session will focus on the collaborative\n",
            "opportunities among indigenous communities, aca\n",
            "\n",
            "Chunk 5 (250 characters):\n",
            "demia,\n",
            "industry, and startups in the creation of indigenous foundational\n",
            "models.\n",
            "Side Event 2 (@ Room The goal of this Convening is to gather insights and feedback on\n",
            "No. X): the use of AI in healthcare to better understand the unique\n",
            "challenges face\n",
            "\n",
            "Chunk 6 (250 characters):\n",
            "d by global south countries in integrating AI\n",
            "GPAI Convening on solutions. The insights gained will help GPAI refine its focus and\n",
            "Global Health and AI explore new directions for future endeavours, ensuring that these\n",
            "issues are addressed from all re\n",
            "\n",
            "Chunk 7 (250 characters):\n",
            "levant contexts and perspectives.\n",
            "This convening will feature experts from various sectors, including\n",
            "government, international organisations, academia, industry, civil\n",
            "society, and other key stakeholders.\n",
            "Lunch: 13:30 - 14:30\n",
            "14:30 –16:30\n",
            "GPAI Sessi\n",
            "\n",
            "Chunk 8 (250 characters):\n",
            "on (@ Summit Room) : Ministerial Council Meeting\n",
            "(By Invitation only)\n",
            "14.30 -16:00 Side Event 3 (@ The case study presentations and panel discussion will bring\n",
            "Auditorium 1): together technical experts to share their experiences of creating\n",
            "real-worl\n",
            "\n",
            "Chunk 9 (250 characters):\n",
            "d solutions, identify gaps in the development and\n",
            "IndiaAI: Real World AI deployment of AI solutions, and discover the next steps in the AI\n",
            "Solutions adoption journey. The learnings of implementing various AI use\n",
            "cases identified through this session \n",
            "\n",
            "Chunk 10 (250 characters):\n",
            "would be the first step in\n",
            "creating a world-class ecosystem that advances the boundaries\n",
            "of AI knowledge and innovation through collaboration with\n",
            "industry, national and international academia, start-ups, and\n",
            "other stakeholders.\n",
            "Side Event 4 (@ Room \n",
            "\n",
            "Chunk 11 (250 characters):\n",
            "The proposed panel discussion will focus on key issues related\n",
            "No. X): to the readiness of infrastructure in India, focusing on strategies\n",
            "for developing scalable and future-ready AI compute\n",
            "IndiaAI: India’s infrastructure. It will emphasise the crit\n",
            "\n",
            "Chunk 12 (250 characters):\n",
            "ical role of a skilled\n",
            "Infrastructure workforce, from chip designers to orchestration engineers, in\n",
            "Readiness for AI establishing robust AI infrastructure. Additionally, the panel will\n",
            "explore strategies to make advanced AI compute services\n",
            "affordabl\n",
            "\n",
            "Chunk 13 (250 characters):\n",
            "e for startups and AI researchers nationwide, ensuring\n",
            "accessibility and fostering innovation.\n",
            "17:00 – 18:30 Side Event 5 (@ This session explores India's commitment to leveraging AI for\n",
            "Auditorium 1): societal good, emphasising the country's strateg\n",
            "\n",
            "Chunk 14 (250 characters):\n",
            "ic approach\n",
            "rooted in openness, safety, trust, and accountability.\n",
            "IndiaAI: Ensuring Discussions will focus on India's efforts to establish ethical\n",
            "Safety, Trust, and guidelines, enhance international cooperation, and prioritise\n",
            "Governance in the AI \n",
            "\n",
            "Chunk 15 (250 characters):\n",
            "safe and trusted AI development, showcasing its dedication to\n",
            "Age creating a secure and trustworthy digital environment.\n",
            "Side Event 6 (@ Room The CAIGP Convening aims to bring together GPAI members,\n",
            "No. X): AI experts and industry representatives to \n",
            "\n",
            "Chunk 16 (250 characters):\n",
            "identify mechanisms\n",
            "to overcome the global AI divide. This session shall be a\n",
            "Collaborative AI on development on previously identified goals of CAIGP, with focus\n",
            "Global Partnership on developing the role of GPAI in aligning global deliberations\n",
            "(CAIG\n",
            "\n",
            "Chunk 17 (250 characters):\n",
            "P) on democratising AI resources and leading the implementation\n",
            "thereof. It shall particularly focus on identifying institutional\n",
            "mechanisms to enable the democratisation of AI resources and\n",
            "its benefits through GPAI. Additionally, focus shall also b\n",
            "\n",
            "Chunk 18 (250 characters):\n",
            "e laid\n",
            "on identifying roles and responsibilities of various stakeholders\n",
            "and ecosystem partners in furthering the thematic objectives of\n",
            "CAIGP.\n",
            "Agenda\n",
            "Global IndiaAI Summit 2024 3-4 July 2024, New Delhi\n",
            "Day 2 - Thursday, July 4\n",
            "Start Session Descript\n",
            "\n",
            "Chunk 19 (250 characters):\n",
            "ion\n",
            "10:00 - 11:30 Side Event 7 (@ The session will focus on the current industry demand, challenges,\n",
            "Room No. Y): and growth in AI skills, highlighting significant opportunities for job\n",
            "seekers. The panel would discuss the importance of AI skilling i\n",
            "\n",
            "Chunk 20 (250 characters):\n",
            "n\n",
            "IndiaAI: today's rapidly evolving technological landscape, emphasizing its\n",
            "Empowering Talent impact on employability, earning potential, and career growth. The\n",
            "through AI session will offer guidance to students, researchers, and\n",
            "Education & Skillin\n",
            "\n",
            "Chunk 21 (250 characters):\n",
            "g professionals on skilling and upskilling opportunities in essential AI\n",
            "technologies and skills, while also showcasing success stories and\n",
            "diverse career paths in AI.\n",
            "Side Event 8 (@ This side session aims to bring together the Global South to\n",
            "Room \n",
            "\n",
            "Chunk 22 (250 characters):\n",
            "No. X): deliberate on the specific challenges and priorities of the Global\n",
            "South for harnessing the potential of AI. The design, development,\n",
            "AI for Global Good: and deployment of artificial intelligence (AI), as well as its associated\n",
            "Empowering the\n",
            "\n",
            "Chunk 23 (250 characters):\n",
            " challenges, have been extensively deliberated by the Global North,\n",
            "Global South largely in the context of their local economies. This has led to AI\n",
            "technology and governance methods being passed down from the\n",
            "(By Invitation only) Global North to the\n",
            "\n",
            "Chunk 24 (250 characters):\n",
            " Global South, without adequate\n",
            "contextualisation. The round table session will also explore\n",
            "mechanisms for empowering the voices of the Global South,\n",
            "including the possibility of creating a new multilateral organisation to\n",
            "help Global South countrie\n",
            "\n",
            "Chunk 25 (250 characters):\n",
            "s gain a voice and bring to the forefront\n",
            "their collective challenges and priorities in the AI development space.\n",
            "12:00 - 13:30 Side Event 9 (@ This side session aims to forge a path towards a self-sufficient India,\n",
            "Room No. Y): where the startup eco\n",
            "\n",
            "Chunk 26 (250 characters):\n",
            "system not only thrives on its own merits but\n",
            "also contributes significantly to the global market. It seeks to\n",
            "IndiaAI: From Seed acknowledge the strides made through existing initiatives and\n",
            "to Scale- assess the current landscape. The session will e\n",
            "\n",
            "Chunk 27 (250 characters):\n",
            "xplore strategies to\n",
            "Empowering India’s further bolster this growth, ensuring India's AI startups are well-\n",
            "Startup Ecosystem equipped to innovate and expand, reinforcing India's position as a\n",
            "leader in the global AI industry.\n",
            "GPAI Session (@ Room No\n",
            "\n",
            "Chunk 28 (250 characters):\n",
            ". X) : Innovation Workshop Followup\n",
            "Lunch: 13:30 - 14:30\n",
            "14:30 –16:00 Side Event 10 (@ The session aims to explore strategies for developing resilient and\n",
            "Room No. X): scalable data infrastructure to support the growth of the AI\n",
            "ecosystem, with focus\n",
            "\n",
            "Chunk 29 (250 characters):\n",
            " on the importance of robust data\n",
            "IndiaAI: Data governance frameworks that ensure data privacy, security, and\n",
            "Ecosystem ethical use. Additionally, the panel will examine the potential for\n",
            "data sharing frameworks and platforms that enable seamless dat\n",
            "\n",
            "Chunk 30 (250 characters):\n",
            "a\n",
            "exchange while maintaining sovereignty and trust. Lastly, the panel\n",
            "will discuss mitigating data bias to ensure ethical and unbiased AI\n",
            "systems by emphasising data quality, representativeness, and\n",
            "fairness.\n",
            "Side Event 11 (@ This session will explor\n",
            "\n",
            "Chunk 31 (250 characters):\n",
            "e how India is preparing to become \"AI-\n",
            "Room No. Y): ready,\" focusing on the transformative potential of Artificial\n",
            "Intelligence (AI) in public services. To realise this potential, it is\n",
            "crucial to understand the foundational requirements for integra\n",
            "\n",
            "Chunk 32 (250 characters):\n",
            "ting\n",
            "AI Competency AI seamlessly, including digital expertise among government\n",
            "Framework for officials. The session will reference the UNESCO Report on AI\n",
            "Public Sector competencies for civil servants and examine the Capacity Building\n",
            "Commission's (C\n",
            "\n",
            "Chunk 33 (250 characters):\n",
            "BC) framework to develop an AI upskilling\n",
            "roadmap for the Indian public sector. Expert feedback and\n",
            "collaborative discussions will aim to identify specific AI\n",
            "competencies required by public officials and provide actionable\n",
            "guidelines for future trai\n",
            "\n",
            "Chunk 34 (250 characters):\n",
            "ning and capacity-building programs.\n",
            "16:30 -18:00 Side Event 12 (@ Building upon the success of the GPAI virtual convening, the\n",
            "Room No. Y): Global India AI summit will include a dedicated session to further\n",
            "critical discourse on the sub-domains of C\n",
            "\n",
            "Chunk 35 (250 characters):\n",
            "rop Advisory, Market\n",
            "Sustainable Access and Financial Services for Farmers and Climate Resilient\n",
            "Agriculture Agriculture. This upcoming session aims to showcase case study\n",
            "presentation that will be followed by a panel discussion to explore\n",
            "synergies,\n",
            "\n",
            "Chunk 36 (149 characters):\n",
            " and cross sectoral opportunities in implementing AI to\n",
            "enhance yields and inform smallholder farmer efforts for\n",
            "agricultural output\n",
            "18:00: High Tea\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Set up the embedding model\n",
        "OptimumEmbedding.create_and_save_optimum_model(\n",
        "    \"BAAI/bge-small-en-v1.5\", \"./bge_onnx\"\n",
        ")\n",
        "\n",
        "embed_model = OptimumEmbedding(folder_name=\"./bge_onnx\")\n",
        "\n",
        "# Check embedding dimension\n",
        "test_embedding = embed_model.get_text_embedding(\"Test sentence\")\n",
        "print(f\"Embedding dimension: {len(test_embedding)}\")\n",
        "\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_tC3ez93jPo",
        "outputId": "d2da079e-940e-40b7-a6d5-ea1e92fa70c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Framework not specified. Using pt to export the model.\n",
            "Using the export variant default. Available variants are:\n",
            "    - default: The default ONNX variant.\n",
            "\n",
            "***** Exporting submodel 1/1: BertModel *****\n",
            "Using framework PyTorch: 2.2.1+cu121\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved optimum model to ./bge_onnx. Use it with `embed_model = OptimumEmbedding(folder_name='./bge_onnx')`.\n",
            "Embedding dimension: 384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid # Import the uuid module\n",
        "\n",
        "# 4. Send data to vector store and store as embedding\n",
        "# Generate a unique collection name\n",
        "collection_name = f\"pdf_embeddings_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "astra_db_store = AstraDBVectorStore(\n",
        "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
        "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
        "    collection_name=collection_name,\n",
        "    embedding_dimension=len(test_embedding),\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=astra_db_store)\n",
        "\n",
        "# Store all documents in the vector store\n",
        "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context, show_progress=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "b9bcd1a1239f452191e210d2f8ce8828",
            "4642e5c44f3b4f36937d255eae9c32b8",
            "44b58a023dd04aaf89bd34676da31d57",
            "4a3abde13abb42469ee1a1f293a0df1f",
            "3a8cfdfc43d14b83af901c00689b2209",
            "58836647b916416199e220924340d205",
            "c502fefcd99c44409047306a91681408",
            "ab255116fea84e6ba007c58752384b42",
            "53e5347de77c42aa9d4defbbfd05a1dc",
            "a546bd896c3c4a0e8fb93fdb05713494",
            "71a815f95ec24e70b3f21ee402721819",
            "081364ffd0284173957b84ef451b95ed",
            "e951b6c07b4d4b69873976b3e833fdc3",
            "99492b70b1a147158293c1e5e6211d54",
            "6fefd3dc43634fa3ac6737db786a6ca8",
            "52c641ccebb94bf581b1bb6815ea475a",
            "c748af184ecf42219898d43ed38e3eae",
            "d25f94d8e875491089f25b4ed0c57e61",
            "cb5a9b4ebcb14afd9351aa5960d9fee3",
            "2792bdce58154a4bb51eef13ca653a1b",
            "944b33f2beb949dc9525fcdcdb3d9e93",
            "5713e22bea2e4ca2846bf657a3d204fd"
          ]
        },
        "id": "frDbXGR93nIN",
        "outputId": "9f87abc1-a078-4eee-e0c3-ed3e7c4108b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/36 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9bcd1a1239f452191e210d2f8ce8828"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/36 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "081364ffd0284173957b84ef451b95ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Query the data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Example query\n",
        "query_string_1 = \"summary of event?\"\n",
        "response = query_engine.query(query_string_1)\n",
        "print(query_string_1)\n",
        "print(response.response)\n",
        "\n",
        "# Retrieve nodes with scores\n",
        "retriever = index.as_retriever(\n",
        "    vector_store_query_mode=\"default\",\n",
        "    similarity_top_k=10,\n",
        ")\n",
        "\n",
        "nodes_with_scores = retriever.retrieve(query_string_1)\n",
        "print(f\"\\nFound {len(nodes_with_scores)} nodes.\")\n",
        "for idx, node_with_score in enumerate(nodes_with_scores):\n",
        "    print(f\" [{idx}] score = {node_with_score.score:.4f}\")\n",
        "    print(f\" text = {node_with_score.node.text[:180]} ...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "lIfxbL-r3-aX",
        "outputId": "73d332f0-5bdd-4460-9a3a-3a80158d44d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'index' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f8252fbad6d1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 5. Query the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquery_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_query_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Example query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mquery_string_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"summary of event?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Contextual Querying\n",
        "def contextual_query(query, context, query_engine):\n",
        "    \"\"\"Perform a query with added context.\"\"\"\n",
        "    # Combine context with the query\n",
        "    combined_query = f\"{context}\\n{query}\"\n",
        "    response = query_engine.query(combined_query)\n",
        "    return response\n",
        "\n",
        "# Define context for the query\n",
        "context = \"This document discusses various events and their summaries.\"\n",
        "\n",
        "# Perform the contextual query\n",
        "query_string_1 = \"summary of event?\"\n",
        "response_with_context = contextual_query(query_string_1, context, query_engine)\n",
        "\n",
        "# Perform the query without context\n",
        "response_without_context = query_engine.query(query_string_1)\n",
        "\n",
        "# Retrieve nodes with scores for the contextual query\n",
        "nodes_with_scores_context = retriever.retrieve(query_string_1)\n",
        "\n",
        "# Display the results\n",
        "print(\"Response with Context:\")\n",
        "print(response_with_context.response)\n",
        "\n",
        "print(\"\\nTop 10 Nodes with Context:\")\n",
        "for idx, node_with_score in enumerate(nodes_with_scores_context[:10]):\n",
        "    print(f\" [{idx + 1}] score = {node_with_score.score:.4f}\")\n",
        "    print(f\" text = {node_with_score.node.text[:180]} ...\")\n",
        "\n",
        "# Perform the query without context and retrieve nodes\n",
        "nodes_with_scores_no_context = retriever.retrieve(query_string_1)\n",
        "\n",
        "print(\"\\nResponse without Context:\")\n",
        "print(response_without_context.response)\n",
        "\n",
        "print(\"\\nTop 10 Nodes without Context:\")\n",
        "for idx, node_with_score in enumerate(nodes_with_scores_no_context[:10]):\n",
        "    print(f\" [{idx + 1}] score = {node_with_score.score:.4f}\")\n",
        "    print(f\" text = {node_with_score.node.text[:180]} ...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hilKtskuG1Jm",
        "outputId": "f3c41b29-c936-4e3a-c80a-05569864b066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response with Context:\n",
            "Sure, I'd be happy to help summarize an event from the provided context. \n",
            "\n",
            "One of the events is a side event taking place in Large Auditorium 1 from 1:30 to 13:00. This event is focused on Large Language Models (LLMs) and Large Multimodal Models (LMMs). The aim of this session is to facilitate learning and sharing of knowledge related to the unique linguistic and cultural diversity that these models can handle. \n",
            "\n",
            "I hope this summary is helpful! If you have any other questions, feel free to ask.\n",
            "\n",
            "Top 10 Nodes with Context:\n",
            " [1] score = 0.8583\n",
            " text = 1:30 - 13:00 Side Event 1 (@ The session is about learning and sharing knowledge on Large\n",
            "Auditorium 1): Language Models (LLMs) and Large Multimodal Models (LMMs),\n",
            "with the aim to  ...\n",
            " [2] score = 0.8538\n",
            " text = on (@ Summit Room) : Ministerial Council Meeting\n",
            "(By Invitation only)\n",
            "14.30 -16:00 Side Event 3 (@ The case study presentations and panel discussion will bring\n",
            "Auditorium 1): toget ...\n",
            " [3] score = 0.8393\n",
            " text = . X) : Innovation Workshop Followup\n",
            "Lunch: 13:30 - 14:30\n",
            "14:30 –16:00 Side Event 10 (@ The session aims to explore strategies for developing resilient and\n",
            "Room No. X): scalable dat ...\n",
            " [4] score = 0.8343\n",
            " text = ning and capacity-building programs.\n",
            "16:30 -18:00 Side Event 12 (@ Building upon the success of the GPAI virtual convening, the\n",
            "Room No. Y): Global India AI summit will include a d ...\n",
            " [5] score = 0.8326\n",
            " text = ion\n",
            "10:00 - 11:30 Side Event 7 (@ The session will focus on the current industry demand, challenges,\n",
            "Room No. Y): and growth in AI skills, highlighting significant opportunities fo ...\n",
            " [6] score = 0.8292\n",
            " text = levant contexts and perspectives.\n",
            "This convening will feature experts from various sectors, including\n",
            "government, international organisations, academia, industry, civil\n",
            "society, an ...\n",
            " [7] score = 0.8282\n",
            " text = s gain a voice and bring to the forefront\n",
            "their collective challenges and priorities in the AI development space.\n",
            "12:00 - 13:30 Side Event 9 (@ This side session aims to forge a pa ...\n",
            " [8] score = 0.8261\n",
            " text = g professionals on skilling and upskilling opportunities in essential AI\n",
            "technologies and skills, while also showcasing success stories and\n",
            "diverse career paths in AI.\n",
            "Side Event 8 ...\n",
            " [9] score = 0.8193\n",
            " text = e for startups and AI researchers nationwide, ensuring\n",
            "accessibility and fostering innovation.\n",
            "17:00 – 18:30 Side Event 5 (@ This session explores India's commitment to leveraging  ...\n",
            " [10] score = 0.8140\n",
            " text = Agenda\n",
            "Global IndiaAI Summit 2024 3-4 July 2024, New Delhi\n",
            "Day 1 - Wednesday, July 3\n",
            "Start Session Description\n",
            "10:00 - 11:00\n",
            "Opening Ceremony (Auditorium 1)\n",
            "11:00 – 13:30\n",
            "GPAI Sess ...\n",
            "\n",
            "Response without Context:\n",
            "From 1:30 to 13:00, there is a side event focused on Language Models (LLMs) and Large Multimodal Models (LMMs) in Large Auditorium 1. This event aims to facilitate learning and sharing of knowledge related to the unique linguistic and cultural diversity associated with these models.\n",
            "\n",
            "From 14:30 to 16:00, there is another side event taking place in Auditorium 1. This event consists of case study presentations and a panel discussion, where technical experts will share their experiences of creating real-world applications.\n",
            "\n",
            "There is also a Ministerial Council Meeting, which is a by-invitation-only event taking place in the Summit Room during this time frame.\n",
            "\n",
            "Top 10 Nodes without Context:\n",
            " [1] score = 0.8583\n",
            " text = 1:30 - 13:00 Side Event 1 (@ The session is about learning and sharing knowledge on Large\n",
            "Auditorium 1): Language Models (LLMs) and Large Multimodal Models (LMMs),\n",
            "with the aim to  ...\n",
            " [2] score = 0.8538\n",
            " text = on (@ Summit Room) : Ministerial Council Meeting\n",
            "(By Invitation only)\n",
            "14.30 -16:00 Side Event 3 (@ The case study presentations and panel discussion will bring\n",
            "Auditorium 1): toget ...\n",
            " [3] score = 0.8393\n",
            " text = . X) : Innovation Workshop Followup\n",
            "Lunch: 13:30 - 14:30\n",
            "14:30 –16:00 Side Event 10 (@ The session aims to explore strategies for developing resilient and\n",
            "Room No. X): scalable dat ...\n",
            " [4] score = 0.8343\n",
            " text = ning and capacity-building programs.\n",
            "16:30 -18:00 Side Event 12 (@ Building upon the success of the GPAI virtual convening, the\n",
            "Room No. Y): Global India AI summit will include a d ...\n",
            " [5] score = 0.8326\n",
            " text = ion\n",
            "10:00 - 11:30 Side Event 7 (@ The session will focus on the current industry demand, challenges,\n",
            "Room No. Y): and growth in AI skills, highlighting significant opportunities fo ...\n",
            " [6] score = 0.8292\n",
            " text = levant contexts and perspectives.\n",
            "This convening will feature experts from various sectors, including\n",
            "government, international organisations, academia, industry, civil\n",
            "society, an ...\n",
            " [7] score = 0.8282\n",
            " text = s gain a voice and bring to the forefront\n",
            "their collective challenges and priorities in the AI development space.\n",
            "12:00 - 13:30 Side Event 9 (@ This side session aims to forge a pa ...\n",
            " [8] score = 0.8261\n",
            " text = g professionals on skilling and upskilling opportunities in essential AI\n",
            "technologies and skills, while also showcasing success stories and\n",
            "diverse career paths in AI.\n",
            "Side Event 8 ...\n",
            " [9] score = 0.8193\n",
            " text = e for startups and AI researchers nationwide, ensuring\n",
            "accessibility and fostering innovation.\n",
            "17:00 – 18:30 Side Event 5 (@ This session explores India's commitment to leveraging  ...\n",
            " [10] score = 0.8140\n",
            " text = Agenda\n",
            "Global IndiaAI Summit 2024 3-4 July 2024, New Delhi\n",
            "Day 1 - Wednesday, July 3\n",
            "Start Session Description\n",
            "10:00 - 11:00\n",
            "Opening Ceremony (Auditorium 1)\n",
            "11:00 – 13:30\n",
            "GPAI Sess ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generate Initial Response\n",
        "def generate_response(query, query_engine):\n",
        "    \"\"\"Generate a response based on the user's query.\"\"\"\n",
        "    response = query_engine.query(query)\n",
        "    return response.response\n",
        "\n",
        "# Example usage for generating a response\n",
        "original_query = \"summary of event\"\n",
        "initial_response = generate_response(original_query, query_engine)\n",
        "\n",
        "print(\"User Query:\", original_query)\n",
        "print(\"Initial AI Response:\", initial_response)\n",
        "\n",
        "# 2. Re-ranking\n",
        "def rerank_results(nodes_with_scores, context, option):\n",
        "    \"\"\"Re-rank the results based on various scoring mechanisms.\"\"\"\n",
        "\n",
        "    # Create a list to hold nodes and their context scores\n",
        "    scored_nodes = []\n",
        "\n",
        "    if option == 1:  # Option 1: Re-rank based on the presence of context words\n",
        "        context_words = set(context.lower().split())\n",
        "        for node_with_score in nodes_with_scores:\n",
        "            context_score = sum(1 for word in context_words if word in node_with_score.node.text.lower())\n",
        "            scored_nodes.append((node_with_score, context_score))\n",
        "\n",
        "    elif option == 2:  # Option 2: Re-rank based on original score only\n",
        "        for node_with_score in nodes_with_scores:\n",
        "            scored_nodes.append((node_with_score, 0))  # No context score, only use original score\n",
        "\n",
        "    elif option == 3:  # Option 3: Re-rank based on length of text\n",
        "        for node_with_score in nodes_with_scores:\n",
        "            context_score = len(node_with_score.node.text.split())\n",
        "            scored_nodes.append((node_with_score, context_score))\n",
        "\n",
        "    elif option == 4:  # Option 4: Re-rank based on a combination of context score and original score\n",
        "        context_words = set(context.lower().split())\n",
        "        for node_with_score in nodes_with_scores:\n",
        "            context_score = (node_with_score.score + sum(1 for word in context_words if word in node_with_score.node.text.lower())) / 2\n",
        "            scored_nodes.append((node_with_score, context_score))\n",
        "\n",
        "    elif option == 5:  # Option 5: Re-rank based on specific keywords\n",
        "        keywords = set([\"event\", \"success\", \"attendees\"])  # Example keywords\n",
        "        for node_with_score in nodes_with_scores:\n",
        "            context_score = sum(1 for word in keywords if word in node_with_score.node.text.lower())\n",
        "            scored_nodes.append((node_with_score, context_score))\n",
        "\n",
        "    # Sort by context score and then by original score\n",
        "    reranked_nodes = sorted(scored_nodes, key=lambda x: (x[1], x[0].score), reverse=True)\n",
        "\n",
        "    return [node for node, _ in reranked_nodes]  # Return only the nodes\n",
        "\n",
        "# Retrieve nodes with scores\n",
        "query_string_1 = \"summary of event?\"\n",
        "nodes_with_scores = retriever.retrieve(query_string_1)\n",
        "\n",
        "# Iterate over each re-ranking option and generate a new response\n",
        "for option in range(1, 6):  # Options 1 to 5\n",
        "    reranked_nodes = rerank_results(nodes_with_scores, context, option)\n",
        "\n",
        "    # Generate a new response based on the highest-ranked node\n",
        "    if reranked_nodes:\n",
        "        top_node = reranked_nodes[0]  # Get the highest-ranked node\n",
        "        new_response = generate_response(top_node.node.text, query_engine)  # Generate response using the text of the top node\n",
        "\n",
        "        # Display the new response first\n",
        "        print(f\"\\nNew Response with Re-ranking Option {option}:\")\n",
        "        print(new_response)\n",
        "\n",
        "        # Then display the top node and its score\n",
        "        print(f\"\\nTop Node with Score for Re-ranking Option {option}:\")\n",
        "        print(f\"Node Text: {top_node.node.text[:180]} ...\")\n",
        "        print(f\"Score: {top_node.score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuQhFO79Hrw7",
        "outputId": "1d2bfb73-daa1-48cc-e64e-be885da8d595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Query: summary of event\n",
            "Initial AI Response: The first side event, taking place in Large Auditorium 1 from 1:30 to 13:00, focuses on Language Models (LLMs) and Large Multimodal Models (LMMs). The goal of this session is to learn about and discuss the unique linguistic and cultural diversity associated with these models.\n",
            "\n",
            "The second event is a Ministerial Council Meeting, which is a by-invitation-only gathering in the Summit Room.\n",
            "\n",
            "The third side event occurs in Large Auditorium 1 from 14:30 to 16:00 and features case study presentations and a panel discussion. Technical experts will share their experiences related to creating real-world applications involving these models.\n",
            "\n",
            "New Response with Re-ranking Option 1:\n",
            "The convening will include a diverse group of experts representing various sectors such as government, international organizations, academia, industry, civil society, and other important stakeholders. This gathering aims to bring together different perspectives and contexts to address the global AI divide and identify mechanisms for collaboration in AI development. The session will take place after lunch, from 14:30 to 16:30, and is part of the GPAI (Global Partnership on Artificial Intelligence) series of discussions focused on aligning global deliberations on the role of AI.\n",
            "\n",
            "Top Node with Score for Re-ranking Option 1:\n",
            "Node Text: levant contexts and perspectives.\n",
            "This convening will feature experts from various sectors, including\n",
            "government, international organisations, academia, industry, civil\n",
            "society, an ...\n",
            "Score: 0.8292\n",
            "\n",
            "New Response with Re-ranking Option 2:\n",
            "The focus of the 1:30 - 13:00 Side Event 1 in Auditorium 1 is to learn and share knowledge on Language Models (LLMs) and Large Multimodal Models (LMMs). The objective is to explore the unique linguistic and cultural diversity of India, with a particular interest in how LLMs can effectively address challenges associated with multilingualism. Additionally, the session will delve into the ethical considerations and biases linked to these models, fostering a discussion on responsible development and deployment.\n",
            "\n",
            "Top Node with Score for Re-ranking Option 2:\n",
            "Node Text: 1:30 - 13:00 Side Event 1 (@ The session is about learning and sharing knowledge on Large\n",
            "Auditorium 1): Language Models (LLMs) and Large Multimodal Models (LMMs),\n",
            "with the aim to  ...\n",
            "Score: 0.8583\n",
            "\n",
            "New Response with Re-ranking Option 3:\n",
            "This side event provides a platform for startups and AI researchers to highlight their collective challenges and priorities in the AI development space. It takes place from 12:00 to 13:30 in Room No. Y, and is part of the efforts to pave the way towards a self-sufficient India. The event is expected to foster innovation and accessibility in the startup ecosystem.\n",
            "\n",
            "Top Node with Score for Re-ranking Option 3:\n",
            "Node Text: s gain a voice and bring to the forefront\n",
            "their collective challenges and priorities in the AI development space.\n",
            "12:00 - 13:30 Side Event 9 (@ This side session aims to forge a pa ...\n",
            "Score: 0.8282\n",
            "\n",
            "New Response with Re-ranking Option 4:\n",
            "The convening will include a diverse group of experts representing various sectors such as government, international organizations, academia, industry, civil society, and other important stakeholders. This gathering aims to bring together different perspectives and contexts, leveraging the collective knowledge and experience of these experts to address the global AI divide. The session will take place after lunch, from 14:30 to 16:30, and will focus on identifying mechanisms to develop the role of GPAI in aligning global deliberations, building upon previously identified goals of the CAIGP.\n",
            "\n",
            "Top Node with Score for Re-ranking Option 4:\n",
            "Node Text: levant contexts and perspectives.\n",
            "This convening will feature experts from various sectors, including\n",
            "government, international organisations, academia, industry, civil\n",
            "society, an ...\n",
            "Score: 0.8292\n",
            "\n",
            "New Response with Re-ranking Option 5:\n",
            "The Global India AI summit will feature a session from 16:30 to 18:00 in Room No. Y, focusing on building upon the success of the GPAI virtual convening. This dedicated session will aim to delve deeper into the sub-domains of a particular area, C, and promote critical discourse on it. This aligns with the summit's goal of fostering innovation and capacity-building programs for startups and AI researchers nationwide. Additionally, there will be another session from 17:00 to 18:30 in Auditorium 1, emphasizing India's commitment to leveraging AI for societal good.\n",
            "\n",
            "Top Node with Score for Re-ranking Option 5:\n",
            "Node Text: ning and capacity-building programs.\n",
            "16:30 -18:00 Side Event 12 (@ Building upon the success of the GPAI virtual convening, the\n",
            "Room No. Y): Global India AI summit will include a d ...\n",
            "Score: 0.8343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Initial Response Generation\n",
        "def generate_response(query, query_engine):\n",
        "    \"\"\"Generate a response based on the user's query.\"\"\"\n",
        "    response = query_engine.query(query)\n",
        "    return response.response\n",
        "\n",
        "# Example usage\n",
        "original_query = \"summary of event\"\n",
        "initial_response = generate_response(original_query, query_engine)\n",
        "\n",
        "print(\"User Query:\", original_query)\n",
        "print(\"Initial AI Response:\", initial_response)\n",
        "\n",
        "def collect_user_feedback(response, is_helpful):\n",
        "    \"\"\"Collect user feedback on the generated response.\"\"\"\n",
        "    # This function simulates collecting feedback from the user\n",
        "    feedback = {\n",
        "        'response': response,\n",
        "        'is_helpful': is_helpful\n",
        "    }\n",
        "    # Store feedback for future analysis\n",
        "    # In practice, you would save this to a database or file\n",
        "    print(\"Feedback collected:\", feedback)\n",
        "    return feedback\n",
        "\n",
        "# Prompt user for feedback on the initial response\n",
        "user_feedback = input(\"Was the initial response helpful? (yes/no): \")\n",
        "is_helpful = user_feedback.lower() == \"yes\"\n",
        "\n",
        "# Collect user feedback\n",
        "user_feedback = collect_user_feedback(initial_response, is_helpful)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1emg42mtI9b9",
        "outputId": "b20a21de-bcc2-402a-c770-189a95cd1cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Query: summary of event\n",
            "Initial AI Response: From 1:30 to 13:00, there is an event in Large Auditorium 1 focused on Language Models (LLMs) and Large Multimodal Models (LMMs). This session aims to facilitate learning and sharing of knowledge about the unique linguistic and cultural diversity associated with these models.\n",
            "\n",
            "Later, from 14:30 to 16:00, there is another event in the Summit Room, which is a Ministerial Council Meeting. This meeting is by invitation only.\n",
            "\n",
            "Lastly, from 14:30 to 16:00, there is a Side Event 3 in Auditorium 1. This event consists of case study presentations and a panel discussion, where technical experts share their experiences of working in the real world.\n",
            "Was the initial response helpful? (yes/no): no\n",
            "Feedback collected: {'response': 'From 1:30 to 13:00, there is an event in Large Auditorium 1 focused on Language Models (LLMs) and Large Multimodal Models (LMMs). This session aims to facilitate learning and sharing of knowledge about the unique linguistic and cultural diversity associated with these models.\\n\\nLater, from 14:30 to 16:00, there is another event in the Summit Room, which is a Ministerial Council Meeting. This meeting is by invitation only.\\n\\nLastly, from 14:30 to 16:00, there is a Side Event 3 in Auditorium 1. This event consists of case study presentations and a panel discussion, where technical experts share their experiences of working in the real world.', 'is_helpful': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Incorporating Feedback into Prompt with Context\n",
        "def generate_response_with_feedback(query, original_response, feedback):\n",
        "    \"\"\"Generate a response using the original query, AI's response, and user feedback.\"\"\"\n",
        "    # Combine the query, original response, and feedback into a prompt\n",
        "    prompt = (\n",
        "        f\"User query: {query}\\n\"\n",
        "        f\"Original AI response: {original_response}\\n\"\n",
        "        f\"User feedback: {'Helpful' if feedback['is_helpful'] else 'Not Helpful'}\\n\"\n",
        "        f\"Based on the query and feedback, generate a more helpful response:\"\n",
        "    )\n",
        "\n",
        "    # Use the prompt to generate a new response\n",
        "    new_response = query_engine.query(prompt)\n",
        "\n",
        "    return new_response.response\n",
        "\n",
        "# Generate a new response using the original query, initial response, and feedback\n",
        "new_response = generate_response_with_feedback(original_query, initial_response, user_feedback)\n",
        "\n",
        "print(\"\\nUser Feedback:\", \"Helpful\" if user_feedback['is_helpful'] else \"Not Helpful\")\n",
        "print(\"\\nNew Response (with Feedback):\")\n",
        "print(new_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDuKBODLJJZt",
        "outputId": "750441c1-45e2-4d1c-ed74-550ac8937b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User Feedback: Not Helpful\n",
            "\n",
            "New Response (with Feedback):\n",
            "The event from 1:30 to 13:00, held in Large Auditorium 1, is dedicated to exploring Language Models (LLMs) and Large Multimodal Models (LMMs). This session offers an opportunity to learn about and discuss the unique linguistic and cultural aspects related to these models.\n",
            "\n",
            "In the afternoon, there are two concurrent events. The first one, taking place in a designated room, is a Ministerial Council Meeting. This meeting is exclusive and open only by invitation.\n",
            "\n",
            "The second event, happening in Auditorium 1, is Side Event 3. This session features case study presentations and a panel discussion, allowing technical experts to share their practical experiences in the field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Query Expansion\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def expand_query(original_query, documents, num_expansions=3):\n",
        "    \"\"\"Expand the query using related terms from the document set.\"\"\"\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "    # Transform the original query into a vector\n",
        "    query_vector = vectorizer.transform([original_query])\n",
        "\n",
        "    # Calculate cosine similarity between the query and documents\n",
        "    cosine_similarities = (tfidf_matrix * query_vector.T).toarray().flatten()\n",
        "\n",
        "    # Get indices of the top N most similar documents\n",
        "    top_indices = cosine_similarities.argsort()[-num_expansions:][::-1]\n",
        "\n",
        "    # Extract the top terms from the most similar documents\n",
        "    related_terms = set()\n",
        "    for index in top_indices:\n",
        "        terms = vectorizer.get_feature_names_out()\n",
        "        # Get the terms from the document\n",
        "        document_terms = tfidf_matrix[index].toarray().flatten()\n",
        "        # Add the top terms to the related terms set\n",
        "        for term, score in zip(terms, document_terms):\n",
        "            if score > 0.1:  # Only include terms with a significant score\n",
        "                related_terms.add(term)\n",
        "\n",
        "    # Combine original query with related terms\n",
        "    expanded_query = f\"{original_query} {' '.join(related_terms)}\"\n",
        "    return expanded_query\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    \"The event was a great success with many attendees.\",\n",
        "    \"Attendees enjoyed various activities and networking opportunities.\",\n",
        "    \"The conference covered a range of topics relevant to the industry.\"\n",
        "]\n",
        "\n",
        "# Original query\n",
        "original_query = \"summary of event\"\n",
        "\n",
        "# Expand the query\n",
        "expanded_query = expand_query(original_query, documents)\n",
        "\n",
        "# Print the original and expanded queries\n",
        "print(\"Original Query:\", original_query)\n",
        "print(\"Expanded Query:\", expanded_query)\n",
        "\n",
        "# Generate responses for both queries\n",
        "original_response = generate_response(original_query, query_engine)\n",
        "expanded_response = generate_response(expanded_query, query_engine)\n",
        "\n",
        "# Print the responses\n",
        "print(\"\\nResponse for Original Query:\")\n",
        "print(original_response)\n",
        "print(\"\\nResponse for Expanded Query:\")\n",
        "print(expanded_response)\n",
        "\n",
        "# Instructions for Students:\n",
        "# - To explore different queries, change the `original_query` variable to a new query.\n",
        "# - Edit the `documents` list to include content that is relevant to the new query.\n",
        "# - Rerun the cell to see how the expanded query and responses change based on the new input."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBo5FMalOrF9",
        "outputId": "321b574e-41b6-4f02-f798-f0f031db4397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Query: summary of event\n",
            "Expanded Query: summary of event great opportunities activities various covered relevant topics attendees success conference enjoyed industry event range networking\n",
            "\n",
            "Response for Original Query:\n",
            "The events scheduled are focused on knowledge sharing and learning. The first side event, taking place in Large Auditorium 1 from 1:30 to 13:00, is centered around Language Models (LLMs) and Large Multimodal Models (LMMs), aiming to explore their unique linguistic and cultural diversity. The second event is a Ministerial Council Meeting, which is by invitation only and will be held in the Summit Room. The final side event, from 14:30 to 16:00 in Large Auditorium 1, consists of case study presentations and a panel discussion, bringing together technical experts to share their experiences in real-world settings.\n",
            "\n",
            "Response for Expanded Query:\n",
            "The event provided great opportunities for attendees to explore various relevant topics in the AI industry. The activities included presentations of case studies and panel discussions, which were led by technical experts sharing their experiences in creating real-world applications. Success stories were showcased, highlighting diverse career paths in AI. The conference was enjoyed by many, offering a range of networking opportunities for professionals to connect and discuss skilling and upskilling opportunities in essential AI technologies and skills.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9bcd1a1239f452191e210d2f8ce8828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4642e5c44f3b4f36937d255eae9c32b8",
              "IPY_MODEL_44b58a023dd04aaf89bd34676da31d57",
              "IPY_MODEL_4a3abde13abb42469ee1a1f293a0df1f"
            ],
            "layout": "IPY_MODEL_3a8cfdfc43d14b83af901c00689b2209"
          }
        },
        "4642e5c44f3b4f36937d255eae9c32b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58836647b916416199e220924340d205",
            "placeholder": "​",
            "style": "IPY_MODEL_c502fefcd99c44409047306a91681408",
            "value": "Parsing nodes: 100%"
          }
        },
        "44b58a023dd04aaf89bd34676da31d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab255116fea84e6ba007c58752384b42",
            "max": 36,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53e5347de77c42aa9d4defbbfd05a1dc",
            "value": 36
          }
        },
        "4a3abde13abb42469ee1a1f293a0df1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a546bd896c3c4a0e8fb93fdb05713494",
            "placeholder": "​",
            "style": "IPY_MODEL_71a815f95ec24e70b3f21ee402721819",
            "value": " 36/36 [00:00&lt;00:00, 850.41it/s]"
          }
        },
        "3a8cfdfc43d14b83af901c00689b2209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58836647b916416199e220924340d205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c502fefcd99c44409047306a91681408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab255116fea84e6ba007c58752384b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e5347de77c42aa9d4defbbfd05a1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a546bd896c3c4a0e8fb93fdb05713494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a815f95ec24e70b3f21ee402721819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "081364ffd0284173957b84ef451b95ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e951b6c07b4d4b69873976b3e833fdc3",
              "IPY_MODEL_99492b70b1a147158293c1e5e6211d54",
              "IPY_MODEL_6fefd3dc43634fa3ac6737db786a6ca8"
            ],
            "layout": "IPY_MODEL_52c641ccebb94bf581b1bb6815ea475a"
          }
        },
        "e951b6c07b4d4b69873976b3e833fdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c748af184ecf42219898d43ed38e3eae",
            "placeholder": "​",
            "style": "IPY_MODEL_d25f94d8e875491089f25b4ed0c57e61",
            "value": "Generating embeddings: 100%"
          }
        },
        "99492b70b1a147158293c1e5e6211d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5a9b4ebcb14afd9351aa5960d9fee3",
            "max": 36,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2792bdce58154a4bb51eef13ca653a1b",
            "value": 36
          }
        },
        "6fefd3dc43634fa3ac6737db786a6ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_944b33f2beb949dc9525fcdcdb3d9e93",
            "placeholder": "​",
            "style": "IPY_MODEL_5713e22bea2e4ca2846bf657a3d204fd",
            "value": " 36/36 [00:01&lt;00:00, 20.46it/s]"
          }
        },
        "52c641ccebb94bf581b1bb6815ea475a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c748af184ecf42219898d43ed38e3eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25f94d8e875491089f25b4ed0c57e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5a9b4ebcb14afd9351aa5960d9fee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2792bdce58154a4bb51eef13ca653a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "944b33f2beb949dc9525fcdcdb3d9e93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5713e22bea2e4ca2846bf657a3d204fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}