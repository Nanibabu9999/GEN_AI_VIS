{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ry2Lga8nPqU",
        "outputId": "00af1b80-4b91-459f-f105-3bb6c39d438b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-groq\n",
            "  Downloading llama_index_llms_groq-0.1.4-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-llms-groq)\n",
            "  Downloading llama_index_core-0.10.55-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai-like<0.2.0,>=0.1.3 (from llama-index-llms-groq)\n",
            "  Downloading llama_index_llms_openai_like-0.1.3-py3-none-any.whl (3.0 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (8.5.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.14.1)\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.1 (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq)\n",
            "  Downloading llama_index_llms_openai-0.1.25-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (4.41.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.7)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (24.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.4.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.16.0)\n",
            "Installing collected packages: dirtyjson, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index-core, llama-index-llms-openai, llama-index-llms-openai-like, llama-index-llms-groq\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-core-0.10.55 llama-index-llms-groq-0.1.4 llama-index-llms-openai-0.1.25 llama-index-llms-openai-like-0.1.3 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.35.13 tiktoken-0.7.0 typing-inspect-0.9.0\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.55-py3-none-any.whl (6.8 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.2.8-py3-none-any.whl (13 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: llama-index-core==0.10.55 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.10.55)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.5-py3-none-any.whl (9.3 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.25)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.7-py3-none-any.whl (5.9 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.30-py3-none-any.whl (38 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.35.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.55->llama-index) (1.14.1)\n",
            "Collecting llama-cloud>=0.0.9 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
            "  Downloading llama_cloud-0.0.9-py3-none-any.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.8/146.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.3.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.4.7-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.55->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud>=0.0.9->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.55->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.55->llama-index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.55->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.55->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.55->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.55->llama-index) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.55->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.55->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.55->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.55->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.10.55->llama-index) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.55->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.55->llama-index) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.55->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.55->llama-index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.55->llama-index) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.9->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.9->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.55->llama-index) (1.16.0)\n",
            "Installing collected packages: striprtf, pypdf, llama-cloud, llama-index-legacy, llama-parse, llama-index-readers-file, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed llama-cloud-0.0.9 llama-index-0.10.55 llama-index-agent-openai-0.2.8 llama-index-cli-0.1.12 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.2.5 llama-index-legacy-0.9.48 llama-index-multi-modal-llms-openai-0.1.7 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.30 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.7 pypdf-4.3.0 striprtf-0.0.26\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.2-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.2 pypdfium2-4.30.0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-llms-groq\n",
        "!pip install llama-index\n",
        "!pip install pdfplumber\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.groq import Groq\n",
        "import pdfplumber\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "mpYu_AJ1nii1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an API key at the Groq console (https://console.groq.com/keys)\n",
        "# Then set it to the environment variable GROQ_API_KEY or pass it directly\n",
        "\n",
        "api_key = \"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\"  # Replace with your actual API key\n",
        "llm = Groq(model=\"llama3-70b-8192\", api_key=api_key)\n"
      ],
      "metadata": {
        "id": "yhdSBDWknmlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_with_pdfplumber(pdf_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "pdf_path = \"/content/agenda.pdf\"  # Replace with the path to your PDF file\n",
        "extracted_text = extract_text_with_pdfplumber(pdf_path)\n",
        "print(extracted_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNvBnppqpcE8",
        "outputId": "fa21b7bd-e036-4af1-b91f-ce7e3819c891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agenda\n",
            "Global IndiaAI Summit 2024 3-4 July 2024, New Delhi\n",
            "Day 1 - Wednesday, July 3\n",
            "Start Session Description\n",
            "10:00 - 11:00\n",
            "Opening Ceremony (Auditorium 1)\n",
            "11:00 – 13:30\n",
            "GPAI Session (@ Summit Room) : Executive Council Meeting\n",
            "(By Invitation only)\n",
            "11:30 - 13:00 Side Event 1 (@ The session is about learning and sharing knowledge on Large\n",
            "Auditorium 1): Language Models (LLMs) and Large Multimodal Models (LMMs),\n",
            "with the aim to understand the unique linguistic and cultural\n",
            "IndiaAI: Large diversity inherent to India, examining how LLMs can effectively\n",
            "Language Model address challenges associated with multilingualism. Furthermore,\n",
            "the session will cover the ethical considerations and biases linked\n",
            "to these models, promoting a discussion on responsible AI\n",
            "practices, including fairness, inclusiveness, misinformation\n",
            "mitigation, and intellectual property rights within diverse cultural\n",
            "contexts. Lastly, the session will focus on the collaborative\n",
            "opportunities among indigenous communities, academia,\n",
            "industry, and startups in the creation of indigenous foundational\n",
            "models.\n",
            "Side Event 2 (@ Room The goal of this Convening is to gather insights and feedback on\n",
            "No. X): the use of AI in healthcare to better understand the unique\n",
            "challenges faced by global south countries in integrating AI\n",
            "GPAI Convening on solutions. The insights gained will help GPAI refine its focus and\n",
            "Global Health and AI explore new directions for future endeavours, ensuring that these\n",
            "issues are addressed from all relevant contexts and perspectives.\n",
            "This convening will feature experts from various sectors, including\n",
            "government, international organisations, academia, industry, civil\n",
            "society, and other key stakeholders.\n",
            "Lunch: 13:30 - 14:30\n",
            "14:30 –16:30\n",
            "GPAI Session (@ Summit Room) : Ministerial Council Meeting\n",
            "(By Invitation only)\n",
            "14.30 -16:00 Side Event 3 (@ The case study presentations and panel discussion will bring\n",
            "Auditorium 1): together technical experts to share their experiences of creating\n",
            "real-world solutions, identify gaps in the development and\n",
            "IndiaAI: Real World AI deployment of AI solutions, and discover the next steps in the AI\n",
            "Solutions adoption journey. The learnings of implementing various AI use\n",
            "cases identified through this session would be the first step in\n",
            "creating a world-class ecosystem that advances the boundaries\n",
            "of AI knowledge and innovation through collaboration with\n",
            "industry, national and international academia, start-ups, and\n",
            "other stakeholders.Side Event 4 (@ Room The proposed panel discussion will focus on key issues related\n",
            "No. X): to the readiness of infrastructure in India, focusing on strategies\n",
            "for developing scalable and future-ready AI compute\n",
            "IndiaAI: India’s infrastructure. It will emphasise the critical role of a skilled\n",
            "Infrastructure workforce, from chip designers to orchestration engineers, in\n",
            "Readiness for AI establishing robust AI infrastructure. Additionally, the panel will\n",
            "explore strategies to make advanced AI compute services\n",
            "affordable for startups and AI researchers nationwide, ensuring\n",
            "accessibility and fostering innovation.\n",
            "17:00 – 18:30 Side Event 5 (@ This session explores India's commitment to leveraging AI for\n",
            "Auditorium 1): societal good, emphasising the country's strategic approach\n",
            "rooted in openness, safety, trust, and accountability.\n",
            "IndiaAI: Ensuring Discussions will focus on India's efforts to establish ethical\n",
            "Safety, Trust, and guidelines, enhance international cooperation, and prioritise\n",
            "Governance in the AI safe and trusted AI development, showcasing its dedication to\n",
            "Age creating a secure and trustworthy digital environment.\n",
            "Side Event 6 (@ Room The CAIGP Convening aims to bring together GPAI members,\n",
            "No. X): AI experts and industry representatives to identify mechanisms\n",
            "to overcome the global AI divide. This session shall be a\n",
            "Collaborative AI on development on previously identified goals of CAIGP, with focus\n",
            "Global Partnership on developing the role of GPAI in aligning global deliberations\n",
            "(CAIGP) on democratising AI resources and leading the implementation\n",
            "thereof. It shall particularly focus on identifying institutional\n",
            "mechanisms to enable the democratisation of AI resources and\n",
            "its benefits through GPAI. Additionally, focus shall also be laid\n",
            "on identifying roles and responsibilities of various stakeholders\n",
            "and ecosystem partners in furthering the thematic objectives of\n",
            "CAIGP.Agenda\n",
            "Global IndiaAI Summit 2024 3-4 July 2024, New Delhi\n",
            "Day 2 - Thursday, July 4\n",
            "Start Session Description\n",
            "10:00 - 11:30 Side Event 7 (@ The session will focus on the current industry demand, challenges,\n",
            "Room No. Y): and growth in AI skills, highlighting significant opportunities for job\n",
            "seekers. The panel would discuss the importance of AI skilling in\n",
            "IndiaAI: today's rapidly evolving technological landscape, emphasizing its\n",
            "Empowering Talent impact on employability, earning potential, and career growth. The\n",
            "through AI session will offer guidance to students, researchers, and\n",
            "Education & Skilling professionals on skilling and upskilling opportunities in essential AI\n",
            "technologies and skills, while also showcasing success stories and\n",
            "diverse career paths in AI.\n",
            "Side Event 8 (@ This side session aims to bring together the Global South to\n",
            "Room No. X): deliberate on the specific challenges and priorities of the Global\n",
            "South for harnessing the potential of AI. The design, development,\n",
            "AI for Global Good: and deployment of artificial intelligence (AI), as well as its associated\n",
            "Empowering the challenges, have been extensively deliberated by the Global North,\n",
            "Global South largely in the context of their local economies. This has led to AI\n",
            "technology and governance methods being passed down from the\n",
            "(By Invitation only) Global North to the Global South, without adequate\n",
            "contextualisation. The round table session will also explore\n",
            "mechanisms for empowering the voices of the Global South,\n",
            "including the possibility of creating a new multilateral organisation to\n",
            "help Global South countries gain a voice and bring to the forefront\n",
            "their collective challenges and priorities in the AI development space.\n",
            "12:00 - 13:30 Side Event 9 (@ This side session aims to forge a path towards a self-sufficient India,\n",
            "Room No. Y): where the startup ecosystem not only thrives on its own merits but\n",
            "also contributes significantly to the global market. It seeks to\n",
            "IndiaAI: From Seed acknowledge the strides made through existing initiatives and\n",
            "to Scale- assess the current landscape. The session will explore strategies to\n",
            "Empowering India’s further bolster this growth, ensuring India's AI startups are well-\n",
            "Startup Ecosystem equipped to innovate and expand, reinforcing India's position as a\n",
            "leader in the global AI industry.\n",
            "GPAI Session (@ Room No. X) : Innovation Workshop Followup\n",
            "Lunch: 13:30 - 14:30\n",
            "14:30 –16:00 Side Event 10 (@ The session aims to explore strategies for developing resilient and\n",
            "Room No. X): scalable data infrastructure to support the growth of the AI\n",
            "ecosystem, with focus on the importance of robust data\n",
            "IndiaAI: Data governance frameworks that ensure data privacy, security, and\n",
            "Ecosystem ethical use. Additionally, the panel will examine the potential for\n",
            "data sharing frameworks and platforms that enable seamless data\n",
            "exchange while maintaining sovereignty and trust. Lastly, the panel\n",
            "will discuss mitigating data bias to ensure ethical and unbiased AI\n",
            "systems by emphasising data quality, representativeness, and\n",
            "fairness.\n",
            "Side Event 11 (@ This session will explore how India is preparing to become \"AI-\n",
            "Room No. Y): ready,\" focusing on the transformative potential of Artificial\n",
            "Intelligence (AI) in public services. To realise this potential, it is\n",
            "crucial to understand the foundational requirements for integratingAI Competency AI seamlessly, including digital expertise among government\n",
            "Framework for officials. The session will reference the UNESCO Report on AI\n",
            "Public Sector competencies for civil servants and examine the Capacity Building\n",
            "Commission's (CBC) framework to develop an AI upskilling\n",
            "roadmap for the Indian public sector. Expert feedback and\n",
            "collaborative discussions will aim to identify specific AI\n",
            "competencies required by public officials and provide actionable\n",
            "guidelines for future training and capacity-building programs.\n",
            "16:30 -18:00 Side Event 12 (@ Building upon the success of the GPAI virtual convening, the\n",
            "Room No. Y): Global India AI summit will include a dedicated session to further\n",
            "critical discourse on the sub-domains of Crop Advisory, Market\n",
            "Sustainable Access and Financial Services for Farmers and Climate Resilient\n",
            "Agriculture Agriculture. This upcoming session aims to showcase case study\n",
            "presentation that will be followed by a panel discussion to explore\n",
            "synergies, and cross sectoral opportunities in implementing AI to\n",
            "enhance yields and inform smallholder farmer efforts for\n",
            "agricultural output\n",
            "18:00: High Tea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of questions and their expected answers (true labels)\n",
        "questions_and_answers = [\n",
        "    (\"What is the name of the summit?\", \"Global IndiaAI Summit 2024\"),\n",
        "    (\"When and where is the Global IndiaAI Summit 2024 taking place?\", \"3-4 July 2024, New Delhi\"),\n",
        "    (\"What is the time and venue for the opening ceremony on Day 1?\", \"10:00 - 11:00 at Auditorium 1\"),\n",
        "    (\"What is the GPAI Session about at 11:00 on Day 1?\", \"Executive Council Meeting (By Invitation only)\"),\n",
        "]\n"
      ],
      "metadata": {
        "id": "C1q3uGdNXj-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to ask questions and get predictions from the model\n",
        "def ask_questions(text, questions_and_answers):\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    for question, true_answer in questions_and_answers:\n",
        "        true_labels.append(true_answer)\n",
        "        response = llm.complete(f\"Give exact answers in one or two words based on {text}, always give date as first when answer containts date, for the question: {question}\")\n",
        "        predicted_labels.append(response.text)  # Accessing the text attribute directly\n",
        "\n",
        "    return true_labels, predicted_labels\n",
        "\n",
        "# Example usage\n",
        "true_labels, predicted_labels = ask_questions(extracted_text, questions_and_answers)\n",
        "print(\"True Labels:\")\n",
        "print(true_labels)\n",
        "print(\"Predicted Labels:\")\n",
        "print(predicted_labels)\n",
        "\n",
        "\n",
        "def evaluate_model(true_labels, predicted_labels):\n",
        "    correct_count = 0\n",
        "    total_count = len(true_labels)\n",
        "\n",
        "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
        "        if true_label in predicted_label or predicted_label in true_label:\n",
        "            correct_count += 1\n",
        "\n",
        "    precision = correct_count / total_count\n",
        "    recall = correct_count / total_count\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "precision, recall, f1 = evaluate_model(true_labels, predicted_labels)\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVj8FJLPaW_X",
        "outputId": "e91b3046-36df-4ecb-a14b-59f3c9bbd7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Labels:\n",
            "['Global IndiaAI Summit 2024', '3-4 July 2024, New Delhi', '10:00 - 11:00 at Auditorium 1', 'Executive Council Meeting (By Invitation only)']\n",
            "Predicted Labels:\n",
            "['Global IndiaAI Summit 2024', 'July 3-4, 2024, New Delhi', 'July 3, 10:00 - 11:00, Auditorium 1', 'Executive Council Meeting']\n",
            "Precision: 0.5\n",
            "Recall: 0.5\n",
            "F1 Score: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print each question, true answer, and predicted answer\n",
        "print(\"Comparison of True and Predicted Answers:\")\n",
        "for i, (true_label, predicted_label) in enumerate(zip(true_labels, predicted_labels)):\n",
        "    print(f\"Question {i + 1}:\")\n",
        "    print(f\"True Answer: {true_label}\")\n",
        "    print(f\"Predicted Answer: {predicted_label}\")\n",
        "    if true_label != predicted_label:\n",
        "        print(\"--> Score impacted: Check precision and recall for this question.\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PSBJDYKb6r4",
        "outputId": "b9da0e0d-8381-4f83-c843-6e9ba2abffa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of True and Predicted Answers:\n",
            "Question 1:\n",
            "True Answer: Global IndiaAI Summit 2024\n",
            "Predicted Answer: Global IndiaAI Summit 2024\n",
            "\n",
            "Question 2:\n",
            "True Answer: 3-4 July 2024, New Delhi\n",
            "Predicted Answer: July 3-4, 2024, New Delhi\n",
            "--> Score impacted: Check precision and recall for this question.\n",
            "\n",
            "Question 3:\n",
            "True Answer: 10:00 - 11:00 at Auditorium 1\n",
            "Predicted Answer: July 3, 10:00 - 11:00, Auditorium 1\n",
            "--> Score impacted: Check precision and recall for this question.\n",
            "\n",
            "Question 4:\n",
            "True Answer: Executive Council Meeting (By Invitation only)\n",
            "Predicted Answer: Executive Council Meeting\n",
            "--> Score impacted: Check precision and recall for this question.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_questions(true_labels, predicted_labels):\n",
        "    results = []\n",
        "\n",
        "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
        "        true_set = set(true_label.lower().split())\n",
        "        predicted_set = set(predicted_label.lower().split())\n",
        "\n",
        "        # Calculate metrics\n",
        "        intersection = true_set.intersection(predicted_set)\n",
        "        precision = len(intersection) / len(predicted_set) if len(predicted_set) > 0 else 0\n",
        "        recall = len(intersection) / len(true_set) if len(true_set) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        results.append({\n",
        "            \"True Label\": true_label,\n",
        "            \"Predicted Label\": predicted_label,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1 Score\": f1\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Evaluate questions\n",
        "evaluation_results = evaluate_questions(true_labels, predicted_labels)\n",
        "\n",
        "# Display results for each question\n",
        "for i, result in enumerate(evaluation_results):\n",
        "    print(f\"Question {i + 1}:\")\n",
        "    print(f\"True Label: {result['True Label']}\")\n",
        "    print(f\"Predicted Label: {result['Predicted Label']}\")\n",
        "    print(f\"Precision: {result['Precision']:.2f}\")\n",
        "    print(f\"Recall: {result['Recall']:.2f}\")\n",
        "    print(f\"F1 Score: {result['F1 Score']:.2f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo4aLtl0crj3",
        "outputId": "cf4b9041-9271-4904-d850-03ed759d8e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 1:\n",
            "True Label: Global IndiaAI Summit 2024\n",
            "Predicted Label: Global IndiaAI Summit 2024\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1 Score: 1.00\n",
            "\n",
            "Question 2:\n",
            "True Label: 3-4 July 2024, New Delhi\n",
            "Predicted Label: July 3-4, 2024, New Delhi\n",
            "Precision: 0.80\n",
            "Recall: 0.80\n",
            "F1 Score: 0.80\n",
            "\n",
            "Question 3:\n",
            "True Label: 10:00 - 11:00 at Auditorium 1\n",
            "Predicted Label: July 3, 10:00 - 11:00, Auditorium 1\n",
            "Precision: 0.57\n",
            "Recall: 0.67\n",
            "F1 Score: 0.62\n",
            "\n",
            "Question 4:\n",
            "True Label: Executive Council Meeting (By Invitation only)\n",
            "Predicted Label: Executive Council Meeting\n",
            "Precision: 1.00\n",
            "Recall: 0.50\n",
            "F1 Score: 0.67\n",
            "\n"
          ]
        }
      ]
    }
  ]
}